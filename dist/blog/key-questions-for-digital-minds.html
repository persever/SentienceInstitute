<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

    <meta name="author" content="Sentience Institute" />

    <meta property="og:site_name" content="Sentience Institute" />
    <meta property="fb:app_id" content="302735083502826" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:site" content="@sentienceinst" />

    
    

    
    <meta property="description" content="Digital minds may be a key factor in the way AI develops over the coming years, such that a better understanding may lead to more accurate forecasts, better strategic prioritization, and concrete strategies for AI safety. Here, I briefly scope out some key questions in this area that might be worth further research.
" />
    <meta property="og:description" content="Digital minds may be a key factor in the way AI develops over the coming years, such that a better understanding may lead to more accurate forecasts, better strategic prioritization, and concrete strategies for AI safety. Here, I briefly scope out some key questions in this area that might be worth further research.
" />
    
    
    <title>Sentience Institute | Key Questions for Digital Minds</title>
    <meta property="title" content="Key Questions for Digital Minds" />
    <meta property="og:title" content="Key Questions for Digital Minds" />
    
    
    
    
    <meta property="og:url" content="http://www.sentienceinstitute.org/blog/key-questions-for-digital-minds" />
    <meta property="og:image" content="http://www.sentienceinstitute.org/img/blog/20230306.png" />
    <meta name="twitter:image" content="http://www.sentienceinstitute.org/img/blog/20230306.png" />
    


    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico?v=1">
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,600" rel="stylesheet">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="../css/sentienceinstitute.css?v=2.0.1" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <link href="../css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <nav class="navbar navbar-inverse navbar-toggleable-sm fixed-top">
      <div class="container">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarText" aria-controls="navbarText" aria-expanded="false">
          <span class="navbar-toggler-icon"></span>
        </button>
        <a class="navbar-brand" href="/">
          <!-- <img class="nav-logo" src="../img/logo/SI_logo_white_200px.png"/> -->
          <img class="nav-logo-brandmark" src="../img/logo/SI_brandmark_white_heavier_web.png"/>
          <div class="nav-logo-text">
            <span>Sentience</span>
            <span class="nav-logo-text-institute">Institute</span>
          </div>
        </a>
        <div id="navbarText" class="collapse navbar-collapse">
          <ul class="navbar-nav">
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
                Research<span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
                <li><a href="/research-agenda">Agenda</a></li>
                <li><a href="/reports">Reports</a></li>
                <li><a href="/aims-survey">Artificial Intelligence, Morality, and Sentience (AIMS) Survey</a></li>
                <li><a href="/aft-survey">Animals, Food, and Technology (AFT) Survey</a></li>
                <li><a href="/foundational-questions-summaries">Foundational Questions for Animal Advocacy</a></li>
                <!-- <li><a href="/blog">Blog</a></li> -->
                <!-- <li><a href="/press">Press Releases</a></li> -->
              </ul>
            </li>
            <!-- <li class="nav-item"><a class="nav-link" destination="/media">Media</a></li> -->
            <li class="nav-item"><a class="nav-link" destination="/podcast">Podcast</a></li>
            <li class="nav-item"><a class="nav-link" destination="/blog">Blog</a></li>
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
                About Us<span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
                <!-- <li><a href="/mission">Our Mission</a></li> -->
                <li><a href="/perspective">Our Perspective</a></li>
                <li><a href="/team">Our Team</a></li>
                <li class="nav-item"><a class="nav-link" href="/get-involved">Get Involved</a></li>
                <li><a href="/transparency">Transparency</a></li>
                <!-- <li><a href="/faq">FAQ</a></li> -->
              </ul>
            </li>
            <li class="nav-item nav-donate"><a class="nav-link" destination="/donate">Donate</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>
    




<div class="container image-container" img-id="20230306" style="background-image: url(/img/blog/20230306.png);">
  
  
  

<div data-nosnippet class="container image-info-container">
  <div class="image-credit">
    <i class="material-icons photo-icon">photo_camera</i>
    <span>
      Jacy Reese Anthis / Midjourney
    </span>
  </div>
  <div class="image-title">
    <div class="image-title-text">
      a small digital brain etched on a computer chip floating on a pool of dark blue liquid, 4k, ultrarealism
    </div>
    <div class="arrow-down"></div>
  </div>
</div>


  
</div>

<div class="container first-container gdoc-html-container blog-container key-questions-for-digital-minds-container">
  <div class="title">
    Key Questions for Digital Minds
  </div>
  <div class="author-info">
    
    <div class="author">
      <div class="author-img"><img src="../img/team/jacy.png"/></div>
      <div class="author-name-and-role">
      <div class="author-name">Jacy Reese Anthis<a class="author-twitter" href="https://twitter.com/jacyanthis"><img src="../img/icons/icon_twitter_blue.png"/></a></div>
      <div class="author-role">Co-Founder</div>
    </div>
  </div>
  
  </div>
  <div class="date">
    March 6, 2023
  </div>
  <html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"></head><body class="c22 doc-content"><p class="c2"><span class="c1 c23 c10">Last revised on June 14, 2023.</span></p><p class="c2"><span class="c1">ChatGPT, Sydney, LaMDA, and other large language models (LLMs) have inspired an unprecedented wave of interest in artificial intelligence (AI). Many are asking if these LLMs are not merely problem-solving tools but have mental faculties such as </span><span class="c3 c1"><a class="c0" href="https://ieeexplore.ieee.org/abstract/document/9736644">emotion</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://dl.acm.org/doi/10.5898/JHRI.3.2.Beer">autonomy</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://dl.acm.org/doi/10.1145/191666.191703">socialization</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://arxiv.org/abs/2208.02957">meaning</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://aclanthology.org/2020.acl-main.463/">language</a></span><span class="c1">, and </span><span class="c3 c1"><a class="c0" href="https://philpapers.org/archive/CHACAL-3.pdf">self-awareness</a></span><span class="c1">. I use the term </span><span class="c1 c10">digital mind</span><span class="c1">&nbsp;to </span><span class="c1">refer to an artificial entity with mental faculties</span><span class="c1">.</span><sup class="c1"><a href="#ftnt1" id="ftnt_ref1">[1]</a></sup></p><p class="c2"><span class="c1">These faculties or capabilities may be a key factor in the trajectory of AI in the coming years. A better understanding of them may lead to more accurate forecasts, better strategic prioritization, and concrete strategies for AI safety. Here, I briefly scope out some key questions in this area that may be worth further research. This may be a promising way for social scientists to contribute to AI safety (see </span><span class="c3 c1"><a class="c0" href="https://distill.pub/2019/safety-needs-social-scientists">&ldquo;AI Safety Needs Social Scientists&rdquo;</a></span><span class="c1">), though these questions also invoke philosophy, computer science, and other perspectives.</span></p><a id="t.5c53f4e5b15d6c854b726f27002b3ee06841110a"></a><a id="t.0"></a><table class="c26"><tr class="c25"><td class="c19" colspan="1" rowspan="1"><p class="c2 c14"><span class="c5 c1"></span></p><p class="c4"><span class="c3 c1"><a class="c0" href="#h.7x3w6qgu4amm">What digital minds will exist in short- and long-term futures?</a></span></p><p class="c4"><span class="c3 c1"><a class="c0" href="#h.s5tn5abe0tp7">How will humans react to digital minds?</a></span></p><p class="c4"><span class="c3 c1"><a class="c0" href="#h.mu1banpp4f99">What is the philosophical nature of digital minds?</a></span></p><p class="c4"><span class="c3 c1"><a class="c0" href="#h.ya1p6dbdfhwj">How will digital minds interact, and what kind of society will that create?</a></span></p><p class="c4"><span class="c3 c1"><a class="c0" href="#h.hn23uawvmt7i">What strategies are most promising for improving futures with digital minds?</a></span></p><p class="c4"><span class="c3 c1"><a class="c0" href="#h.iaj8m3gbv7i1">FAQ</a></span></p><p class="c4 c12"><span class="c3 c1"><a class="c0" href="#h.ogve6zttfrgb">What makes this different from other AI existential safety research?</a></span></p><p class="c4 c12"><span class="c3 c1"><a class="c0" href="#h.4min0pq0opcv">How fixed is this agenda?</a></span></p><p class="c4 c12"><span class="c3 c1"><a class="c0" href="#h.lcl1vsp6sb9i">How can I work on digital minds (DM) research?</a></span></p><p class="c2 c14"><span class="c5 c1"></span></p></td></tr></table><p class="c2 c14"><span class="c5 c1"></span></p><h1 class="c16" id="h.7x3w6qgu4amm"><span class="c8">What </span><span class="c8">digital minds</span><span class="c8">&nbsp;will exist in short- and long-term futures?</span></h1><p class="c2"><span class="c1">Th</span><span class="c1">ere are many </span><span class="c1">plausible</span><span class="c1">&nbsp;ways for digital minds to emerge relatively soon in</span><span class="c1">&nbsp;AIs, such as in the new wave of LLMs (e.g., </span><span class="c3 c1"><a class="c0" href="https://openai.com/blog/chatgpt/">ChatGPT</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://twitter.com/kliu128/status/1623472922374574080">Sydney</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://blog.google/technology/ai/bard-google-ai-search-updates/">Bard</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://twitter.com/goodside/status/1611456645737107456">Claude</a></span><span class="c1">, and </span><span class="c3 c1"><a class="c0" href="https://arxiv.org/abs/2209.14375">Sparrow</a></span><span class="c1">). AIs already have </span><span class="c3 c1"><a class="c0" href="https://arxiv.org/abs/2203.02155">reinforcement learning from human feedback (RLHF)</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://arxiv.org/abs/2108.07732">program synthesis</a></span><span class="c1">, and </span><span class="c3 c1"><a class="c0" href="https://arxiv.org/abs/2302.04761">the ability to call APIs</a></span><span class="c1">, and the way minds emerge may depend on myriad social factors such as the different cultures and reputations of AI engineering teams across tech giants, start-ups, universities, and governments.</span><span class="c1">&nbsp;Already in 2022, a few e</span><span class="c1">ngineers</span><span class="c1">&nbsp;saw neural nets as </span><span class="c3 c1"><a class="c0" href="https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/">&ldquo;sentient&rdquo;</a></span><span class="c1">&nbsp;and said they </span><span class="c3 c1"><a class="c0" href="https://twitter.com/ilyasut/status/1491554478243258368?lang%3Den">&ldquo;may be &hellip; slightly conscious.&rdquo;</a></span><span class="c1">&nbsp;In the long run, there are </span><span class="c3 c1"><a class="c0" href="https://philpapers.org/archive/SOTAOA.pdf">many advantages</a></span><span class="c5 c1">&nbsp;to being a digital mind that could lead to their ubiquity, such as a better ability to copy and modify oneself.</span></p><p class="c2"><span class="c1">Forecasting</span><span class="c1">&nbsp;which trajectories are most likely may draw from </span><span class="c3 c1"><a class="c0" href="https://docs.google.com/document/d/1IJ6Sr-gPeXdSJugFulwIpvavc0atjHGM82QjIfUSBGQ/">biology</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://epochai.org/blog/projecting-compute-trends">computer science</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="http://arxiv.org/abs/2206.14576">cognitive science</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://en.wikipedia.org/wiki/The_Age_of_Em">economics</a></span><span class="c1">, and </span><span class="c1">other fields</span><span class="c1">, as well as research directly </span><span class="c3 c1"><a class="c0" href="https://arxiv.org/abs/2207.13243">interpreting</a></span><span class="c1">&nbsp;and </span><span class="c3 c1"><a class="c0" href="https://arxiv.org/abs/2301.05433">explaining</a></span><span class="c1">&nbsp;current AIs. For example, </span><span class="c1">without reinforcement learning, </span><span class="c1">AIs may not have a multi-time-step reasoning</span><span class="c1">&nbsp;that is necessary for some richer mental faculties, </span><span class="c3 c1"><a class="c0" href="https://www.sentienceinstitute.org/blog/assessing-sentience-in-artificial-entities#relevant-features">such as goal-directed behavior</a></span><span class="c1">. On the other hand, given the </span><span class="c3 c1"><a class="c0" href="https://www.metaculus.com/questions/5118/will-robin-hanson-win-a-bet-that-the-gpt-line-of-language-models-will-generate--1bn-in-customer-revenue-by-2025/">marketability</a></span><span class="c1">&nbsp;of LLMs, corporations may drive that technological progress most quickly, and </span><span class="c1">the incentive to have AIs that can predict human behavior (e.g., personal assistants) </span><span class="c1">may quickly lead to digital minds</span><span class="c1">. </span><span class="c1">These different sorts of digital minds may each require different approaches to alignment and existential safety. For example, digital minds with a fundamental capacity for linguistic meaning may be able to interpret human instructions and </span><span class="c1">bootstrap their way into aligned outcomes with RLHF,</span><span class="c1">&nbsp;while </span><span class="c1">highly agentic minds</span><span class="c1">&nbsp;with limited faculties of language and meaning may require more hard-coded alignment</span><span class="c1">, such as </span><span class="c3 c1"><a class="c0" href="https://papers.nips.cc/paper/2021/file/5989add1703e4b0480f75e2390739f34-Paper.pdf">neural causal models</a></span><span class="c1">&nbsp;or </span><span class="c3 c1"><a class="c0" href="https://intelligence.org/files/TechnicalAgenda.pdf">agent foundations</a></span><span class="c1">. These are just some concrete examples of many factors that could drive forecasts related to digital minds, which could complement forecasting of economic trends by </span><span class="c3 c1"><a class="c0" href="https://futuretech.mit.edu/">MIT FutureTech</a></span><span class="c1">, compute trends by </span><span class="c3 c1"><a class="c0" href="https://epochai.org/">Epoch</a></span><span class="c1">, and </span><span class="c3 c1"><a class="c0" href="https://www.metaculus.com/">Metaculus</a></span><span class="c5 c1">&nbsp;prediction markets.</span></p><h1 class="c16" id="h.s5tn5abe0tp7"><span class="c8">How </span><span class="c8">will</span><span class="c8">&nbsp;</span><span class="c8">humans react to digital minds?</span></h1><p class="c2"><span class="c1">Reactions to </span><span class="c1">actual</span><span class="c1">&nbsp;or perceived </span><span class="c1">digital minds</span><span class="c1">&nbsp;may play an important role in existential risks from AI. </span><span class="c3 c1"><a class="c0" href="https://www.nytimes.com/2023/02/22/movies/ai-movies-microsoft-bing-robots.html">People</a></span><span class="c1">&nbsp;</span><span class="c3 c1"><a class="c0" href="https://www.nytimes.com/2023/02/17/opinion/letters/bing-chatbot-kevin-roose.html">are</a></span><span class="c1">&nbsp;</span><span class="c3 c1"><a class="c0" href="https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html">already</a></span><span class="c1">&nbsp;</span><span class="c3 c1"><a class="c0" href="https://www.nytimes.com/2023/02/16/briefing/microsoft-ai-chatbot.html">reacting</a></span><span class="c1">&nbsp;strongly to those dialogue-based LLMs. </span><span class="c1">Mind attribution may effect a rapid increase in AI investments, a shift in prioritization among AI architectures, a </span><span class="c3 c1"><a class="c0" href="https://press.princeton.edu/books/hardcover/9780691172798/the-technology-trap">Ludditic</a></span><span class="c1">&nbsp;backlash against AI progress, </span><span class="c3 c1"><a class="c0" href="https://www.worldscientific.com/doi/10.1142/S270507852150003X">campaigns</a></span><span class="c1">&nbsp;to protect the interests of AI</span><span class="c1">, existential </span><span class="c3 c1"><a class="c0" href="https://www.wired.com/story/picture-limitless-creativity-ai-image-generators/">reflection</a></span><span class="c1">&nbsp;among humans, etc.</span><span class="c1">&nbsp;Human reactions have been the focus of most </span><span class="c3 c1"><a class="c0" href="https://www.sentienceinstitute.org/blog/">Sentience Institute research to date</a></span><span class="c1">, such as the ongoing </span><span class="c3 c1"><a class="c0" href="https://www.sentienceinstitute.org/aims-survey">Artificial Intelligence, Morality, and Sentience (AIMS)</a></span><span class="c1">&nbsp;nationally representative survey of US public attitudes, a survey of </span><span class="c3 c1"><a class="c0" href="https://www.sentienceinstitute.org/downloads/predicting-the-moral-consideration-of-artificial-intelligences.pdf">predictors</a></span><span class="c1">&nbsp;of moral consideration of AIs in </span><span class="c1 c10">Computers in Human Behavior</span><span class="c1">, and preprints of experiments on </span><span class="c3 c1"><a class="c0" href="https://www.sentienceinstitute.org/downloads/Perspective%2520taking%2520and%2520nonhuman%2520groups%2520-%2520preprint.pdf">perspective-taking</a></span><span class="c1">&nbsp;and the effect of different </span><span class="c3 c1"><a class="c0" href="https://psyarxiv.com/235vp/">features</a></span><span class="c5 c1">&nbsp;(e.g., embodiment, emotion expression) on moral consideration.</span></p><p class="c2"><span class="c1">Further research should draw on cognitive and social psychology as well as macro social science across political, media, and social movement theory. For example, mind perception theory </span><span class="c3 c1"><a class="c0" href="https://www.tandfonline.com/doi/full/10.1080/1047840X.2012.651387">suggests</a></span><span class="c1">&nbsp;that attribution of agentic mental capacity is associated with attribution of moral agency&mdash;the ability to take moral action, to create benefit and harm&mdash;while experience is associated with moral </span><span class="c1">patiency</span><span class="c1">&nbsp;(i.e., </span><span class="c3 c1"><a class="c0" href="https://www.sciencedirect.com/science/article/pii/S0016328721000641">moral circle expansion</a></span><span class="c1">); thus, humans may react to more agentic minds with more concern and resistance. </span><span class="c1">Similarly, studies in human-robot interaction suggest that </span><span class="c3 c1"><a class="c0" href="https://www.sciencedirect.com/science/article/abs/pii/S1071581916301768">autonomy</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://onlinelibrary.wiley.com/doi/10.1002/hbe2.147">humanness</a></span><span class="c1">, and </span><span class="c3 c1"><a class="c0" href="https://dl.acm.org/doi/10.5898/JHRI.5.2.Yogeeswaran">outperformance</a></span><span class="c1">&nbsp;make humans feel more threatened. </span><span class="c1">One particularly important dimension may be the extent to which advanced AI systems appear to be aligned, such as through RLHF, even if the underlying model is not viewed as safe and aligned by well-informed researchers. At the macro scale, the history of </span><span class="c3 c1"><a class="c0" href="https://www.sentienceinstitute.org/blog/key-lessons-from-social-movement-history">how historical social movements emerge and succeed</a></span><span class="c1">&nbsp;can evidence how </span><span class="c1">collective action</span><span class="c1 c5">&nbsp;may occur following the recognition of digital minds, particularly the presence of mental faculties in a technological artifact, may create a trajectory that recombines features of social movements and other emerging technologies. Research can also address the extent of value lock-in with various reflection and alignment mechanisms, and thus how and to what extent we should ensure moral progress before takeoff.</span></p><h1 class="c16" id="h.mu1banpp4f99"><span class="c5 c6">What is the philosophical nature of digital minds?</span></h1><p class="c2"><span class="c1">Most</span><span class="c1">&nbsp;digital minds research </span><span class="c1">to date has been in a disciplinary cluster of philosophy of mind, ethics, and law since the 1920 science fiction play </span><span class="c3 c1"><a class="c0" href="https://en.wikipedia.org/wiki/R.U.R.">R.U.R.</a></span><span class="c1">&nbsp;raised questions of robot rights. Much of this literature centers on mental faculties such as consciousness, following the ethics literature on human and nonhuman animals, as well as relational theories that emphasize the social connections we have to AIs, most notably in </span><span class="c3 c1 c10"><a class="c0" href="https://mitpress.mit.edu/9780262038621/robot-rights/">Robot Rights</a></span><span class="c3 c1"><a class="c0" href="https://mitpress.mit.edu/9780262038621/robot-rights/">&nbsp;(Gunkel 2018)</a></span><span class="c1">. We survey the ethics literature, broadly construed, in </span><span class="c3 c1"><a class="c0" href="https://link.springer.com/article/10.1007/s11948-021-00331-8">Harris and Anthis (2021)</a></span><span class="c1">. </span><span class="c1">Our recent paper, </span><span class="c3 c1"><a class="c0" href="https://link.springer.com/article/10.1007/s43681-023-00260-1">Ladak (2023)</a></span><span class="c1">&nbsp;in </span><span class="c1 c10">AI and Ethics</span><span class="c1">, catalogs nine criteria that have been proposed for moral standing, </span><span class="c1">emphasizing non-sentient AIs who arguably still have preferences and goals and thus may warrant moral consideration</span><span class="c1">. Digital minds may have </span><span class="c3 c1"><a class="c0" href="https://twitter.com/anthrupad/status/1622349563922362368">very different</a></span><span class="c1">&nbsp;values and preferences from humans, such as less emphasis on self-preservation and </span><span class="c1">mortal urgency</span><span class="c1">, and we have cataloged some </span><span class="c3 c1"><a class="c0" href="https://www.sentienceinstitute.org/blog/assessing-sentience-in-artificial-entities#relevant-features">relevant features</a></span><span class="c5 c1">&nbsp;for assessing sentience in artificial entities.</span></p><p class="c2"><span class="c5 c1">Properly including AIs in the moral circle could improve human-AI relations, reduce human-AI conflict, and reduce the likelihood of human extinction from rogue AI. Moral circle expansion to include the interests of digital minds may be necessary for AI alignment because of the inherent challenges in aligning the goals of systems that have an exclusionary relationship with each other such as oppression, abuse, cruelty, or slavery.</span></p><p class="c2"><span class="c1">A number of philosophers and scientists have written about whether artificial consciousness is possible. In a recent review, we find </span><span class="c3 c1"><a class="c0" href="https://www.sentienceinstitute.org/blog/is-artificial-consciousness-possible">an affirmative consensus</a></span><span class="c1">, though division remains on its plausibility, especially due to differences between computational, physical, and biological approaches. Progress on this question may be largely tied up in broader challenges in a philosophical understanding of consciousness, such as resolving debates between realism and</span><span class="c3 c1"><a class="c0" href="https://jacyanthis.com/Consciousness_Semanticism.pdf">&nbsp;eliminativism</a></span><span class="c1">, and the developments of scientific theories such as </span><span class="c3 c1"><a class="c0" href="https://en.wikipedia.org/wiki/Global_workspace_theory">global workspace</a></span><span class="c1">&nbsp;and </span><span class="c3 c1"><a class="c0" href="https://en.wikipedia.org/wiki/Attention_schema_theory">attention schema</a></span><span class="c1">. David Chalmer</span><span class="c1">s</span><span class="c1">&nbsp;has </span><span class="c3 c1"><a class="c0" href="https://nips.cc/virtual/2022/invited-talk/55867">recently taken up the question</a></span><span class="c1">&nbsp;of consciousness in language models, covering features such as memory and global workspaces, and </span><span class="c1">philosophy of mind seems to be the main topic for digital minds group at </span><span class="c3 c1"><a class="c0" href="https://www.fhi.ox.ac.uk/the-team/">FHI</a></span><span class="c1">, such as </span><span class="c3 c1"><a class="c0" href="https://nickbostrom.com/papers/digital-minds.pdf">Shulman and Bostrom (2020)</a></span><span class="c1">&nbsp;on superbeneficiaries</span><span class="c1">&mdash;though </span><span class="c3 c1"><a class="c0" href="https://nickbostrom.com/propositions.pdf">Bostrom and Shulman&rsquo;s &ldquo;Propositions Concerning Digital Minds and Society&rdquo; (2022)</a></span><span class="c1">&nbsp;covers a wider range of topics&mdash;as well as for </span><span class="c3 c1"><a class="c0" href="https://sites.google.com/nyu.edu/mindethicspolicy/home">MEP</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://www.fau.edu/future-mind/">CFM</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://gcrinstitute.org/ai/">GCRI</a></span><span class="c5 c1">, and most other academic groups in this nascent field.</span></p><h1 class="c16" id="h.ya1p6dbdfhwj"><span class="c8">How will </span><span class="c8">digital minds </span><span class="c8">interact</span><span class="c8">, and </span><span class="c8">what kind of society</span><span class="c8">&nbsp;will that create?</span></h1><p class="c2"><span class="c1">Given individual differences between d</span><span class="c1">igital and biological minds</span><span class="c1">, there may be radically different social dynamics, such as the wide range of predictions made in </span><span class="c3 c1 c10"><a class="c0" href="https://en.wikipedia.org/wiki/The_Age_of_Em">The Age of Em</a></span><span class="c3 c1"><a class="c0" href="https://en.wikipedia.org/wiki/The_Age_of_Em">&nbsp;(Hanson 2016)</a></span><span class="c1">&nbsp;for a world of whole brain emulations and the conceptual analysis of simulations in </span><span class="c3 c1 c10"><a class="c0" href="https://wwnorton.com/books/reality">Reality+</a></span><span class="c3 c1"><a class="c0" href="https://wwnorton.com/books/reality">&nbsp;(Chalmers 2022)</a></span><span class="c1">. Further work could focus on economic, organizational, or political dynamics, such as trade-offs between AI </span><span class="c3 c1"><a class="c0" href="https://en.wikipedia.org/wiki/The_Second_Machine_Age">augmenting or automating</a></span><span class="c1">&nbsp;human labor, </span><span class="c3 c1"><a class="c0" href="https://www.lesswrong.com/posts/PTzsEQXkCfig9A6AS/transcript-of-sam-altman-s-interview-touching-on-ai-safety">&ldquo;super democratized&rdquo;</a></span><span class="c1">&nbsp;</span><span class="c3 c1"><a class="c0" href="https://www.governance.ai/post/what-do-we-mean-when-we-talk-about-ai-democratisation">access</a></span><span class="c1">&nbsp;to multiple AGIs, or multipolar takeoff scenarios in which transformative AIs </span><span class="c3 c1"><a class="c0" href="https://longtermrisk.org/files/Cooperation-Conflict-and-Transformative-Artificial-Intelligence-A-Research-Agenda.pdf">cooperate or conflict</a></span><span class="c1">. This includes a number of ways in which the long-term future could go </span><span class="c3 c1"><a class="c0" href="https://www.sentienceinstitute.org/blog/the-future-might-not-be-so-great">very well or very poorly</a></span><span class="c5 c1">.</span></p><p class="c2"><span class="c1">The consideration of mental faculties other than intelligence may complicate a variety of social theorie</span><span class="c1">s, such as: game theory with fewer bounds on rationality and cooperation; decision theory with access to other agents&rsquo; source code (a la </span><span class="c3 c1"><a class="c0" href="https://arxiv.org/abs/1710.05060">functional decision theory</a></span><span class="c1">); social choice theory if individuals can quickly copy themselves; organizational and economic theory if the locus of agency is no longer individuals but groups of (near-)copies; and legal and rights theories with digital environments that are easier to surveil, manipulate, and abuse than analog environments. The </span><span class="c1">social dynamics of digital minds</span><span class="c5 c1">, in groups of exclusively digital minds and in hybrid biological-digital groups (e.g., the first digital minds and their human creators), could precipitate very rapid increases in AI capabilities and lead to radically different takeoff scenarios and long-term futures.</span></p><h1 class="c16" id="h.hn23uawvmt7i"><span class="c8">What strategies are most promising for improving futures </span><span class="c8">with </span><span class="c8">digital minds?</span></h1><p class="c2"><span class="c1">All of the foundational research outlined above needs to ultimately be cashed out in better strategies for building the best future for all sentient beings. One tentative strategic claim is that research should be prioritized before other projects such as public policy or outreach. </span><span class="c1">First impressions may be very important for digital minds as with other </span><span class="c1">technosocial</span><span class="c1">&nbsp;issues (e.g., lock-in of </span><span class="c3 c1"><a class="c0" href="https://www.sciencedirect.com/science/article/pii/S0195666319304829">GMO</a></span><span class="c1">&nbsp;and </span><span class="c3 c1"><a class="c0" href="https://www.sentienceinstitute.org/nuclear-power-clean-meat">nuclear energy</a></span><span class="c1">&nbsp;narratives), and there has been so little research on this topic that the most promising outreach strategies could easily change after only a few research projects.</span><span class="c1">&nbsp;</span><span class="c1">Before promoting a narrative or policy goal, such as a </span><span class="c3 c1"><a class="c0" href="https://www.worldscientific.com/doi/abs/10.1142/S270507852150003X">moratorium on digital consciousness</a></span><span class="c1">,</span><span class="c1">&nbsp;</span><span class="c1">we should consider its direct viability and indirect effects of its promotion</span><span class="c5 c1">.</span></p><p class="c2"><span class="c1">Delay should not be too long, however, because suboptimal narratives may take over in the meantime, especially with short timelines&mdash;making digital minds research a highly time-sensitive AI safety project. </span><span class="c3 c1"><a class="c0" href="https://www.washingtonpost.com/technology/2022/07/22/google-ai-lamda-blake-lemoine-fired/">Discussion to date</a></span><span class="c1">&nbsp;has arguably been largely confused and quite possibly detrimental. </span><span class="c1">The most promising work informed by digital minds research may be preparation to push forcefully for certain technical and governance strategies during major advances in AI capabilities</span><span class="c1">.</span></p><h1 class="c16" id="h.iaj8m3gbv7i1"><span class="c5 c6">FAQ</span></h1><h2 class="c13" id="h.ogve6zttfrgb"><span class="c8">What makes this different from other </span><span class="c8">AI existential safety research</span><span class="c5 c8 c17">?</span></h2><p class="c2"><span class="c1">That&rsquo;s a tough question. As with most research clusters, distinctions are more in focus, methods, and </span><span class="c3 c1"><a class="c0" href="https://en.wikipedia.org/wiki/Family_resemblance">family resemblance</a></span><span class="c1">&nbsp;than crisp conceptual boundaries. In practice, this agenda is more oriented towards social science and towards complex, high-level topics than paradigms such as mechanistic interpretability and agent foundations. For example,</span><span class="c1">&nbsp;rather</span><span class="c1">&nbsp;than approaching &ldquo;agency&rdquo; with bottom-up </span><span class="c1 c3"><a class="c0" href="https://www.lesswrong.com/tag/infra-bayesianism">infra-Bayesianism</a></span><span class="c5 c1">, DM research would tend towards social models of agency&mdash;how agents work together and attribute agency to each other&mdash;and utilize social science rather than mathematical tools.</span></p><p class="c2"><span class="c1">Also,</span><span class="c1">&nbsp;many AI safety research agendas have a safe AI architecture in mind (e.g., </span><span class="c3 c1"><a class="c0" href="https://www.lesswrong.com/posts/HqLxuZ4LhaFhmAHWk/iterated-distillation-and-amplification-1">IDA</a></span><span class="c1">), but DM does not. It is better viewed as a question-centric agenda (e.g., &ldquo;How can we </span><span class="c3 c1"><a class="c0" href="https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/">elicit latent knowledge</a></span><span class="c5 c1">?&rdquo;) or a specific stream of forecasting (i.e., marginal and conditional probabilities of particular AI futures). And because it is a high-level approach not specific to an architecture or technical implementation, it may be more robustly useful across possible AI takeoff scenarios, at least those in which AGI has a richer mental life&mdash;though by the same token, it may lack the sharp contribution to specific AI takeoff scenarios.</span></p><h2 class="c13" id="h.4min0pq0opcv"><span class="c5 c8 c17">How fixed is this agenda?</span></h2><p class="c2"><span class="c5 c1">Not at all. There are some exciting individual projects already happening in this nascent field, and now the idea is to zoom out and write this research agenda to figure out which orientations, questions, and clusters of projects seem most promising&mdash;if any. We will continue to iterate between concrete big-picture planning and concrete progress on the most promising individual projects, but overall, this new field seems very promising at the moment.</span></p><h2 class="c13" id="h.lcl1vsp6sb9i"><span class="c5 c8 c17">How can I work on digital minds (DM) research?</span></h2><p class="c2"><span class="c1">This work is now our primary focus at the </span><span class="c3 c1"><a class="c0" href="https://www.sentienceinstitute.org/">Sentience Institute</a></span><span class="c1">. We have </span><span class="c3 c1"><a class="c0" href="https://www.sentienceinstitute.org/blog/eoy2022">substantial room for more funding</a></span><span class="c1">; we are eager to establish a network of DM research collaborators and advisors (</span><span class="c3 c1"><a class="c0" href="mailto:info@sentienceinstitute.org">get in touch</a></span><span class="c1">); and we are accepting </span><span class="c3 c1"><a class="c0" href="https://www.sentienceinstitute.org/get-involved">researcher applications</a></span><span class="c1">&nbsp;on a rolling basis! Some other research groups of particular relevance that you could work with are the </span><span class="c3 c1"><a class="c0" href="https://www.fhi.ox.ac.uk/about-fhi/">FHI digital minds group</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://jonsimon.net/digital-minds-project/">Mila-FHI-UM digital minds project</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://sites.google.com/nyu.edu/mindethicspolicy/home">NYU Mind, Ethics, and Policy program</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://www.fau.edu/future-mind/">FAU Center for the Future Mind</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://gcrinstitute.org/ai/">Global Catastrophic Risk Institute</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://www.frontiersin.org/articles/10.3389/frobt.2021.788355/full">Legal Priorities Project</a></span><span class="c1">, </span><span class="c3 c1"><a class="c0" href="https://centerforreducingsuffering.org/research/#S-Risks">Center for Reducing Suffering</a></span><span class="c1">, and </span><span class="c3 c1"><a class="c0" href="https://longtermrisk.org/research-agenda">Center on Long-Term Risk</a></span><span class="c5 c1">.</span></p><p class="c2"><span class="c1 c10">Thanks for feedback on versions of this essay from Seth Baum, Tobias Baumann, Max Carpendale, Michael Chen, Michael Dello-Iacovo, Zach Freitas-Groff, Oscar Horta, Roman Leventov, David Manheim, Caleb Ontiveros, Janet V. T. Pauketat, Sean Richardson, Brad Saad, Yip Fai Tse, Earl J. Wagner, Jamie Woodhouse, and Miranda Zhang.</span></p><div><p class="c7"><span class="c5 c21 c24"></span></p><p class="c14 c20"><span class="c5 c21 c24"></span></p></div><hr class="c15"><div><p class="c18"><a href="#ftnt_ref1" id="ftnt1">[1]</a><span class="c11">&nbsp;</span><span class="c8 c11">The first usage of the term &ldquo;digital minds&rdquo; in this context that I know of was Bart Kosko&rsquo;s </span><span class="c3 c8 c10 c11"><a class="c0" href="https://www.google.com/books/edition/The_Fuzzy_Future/w8vaAAAAMAAJ">The Fuzzy Future: From Society and Science to Heaven in a Chip</a></span><span class="c3 c8 c11"><a class="c0" href="https://www.google.com/books/edition/The_Fuzzy_Future/w8vaAAAAMAAJ">&nbsp;(1999)</a></span><span class="c8 c11">, when referring to a human brain with its neurons gradually replaced by computer chips</span><span class="c8 c11">. As far as I know, my usage here is the first explicit definition.</span></p></div></body></html>
</div>




    <hr>
    <div class="container newsletter-container ">
      <p>Subscribe to our newsletter to receive updates on our research and activities. We average one to two emails per year.</p>
      <div id="mc_embed_signup">
        <form action="//sentienceinstitute.us15.list-manage.com/subscribe/post?u=d898f823d035e0601866e68d6&amp;id=cbf2d915a6" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
          <div id="mc_embed_signup_scroll">
            <input type="email" value="" name="EMAIL" class="email form-input" id="mce-EMAIL" placeholder="Email address" required>
            <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
            <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_d898f823d035e0601866e68d6_cbf2d915a6" tabindex="-1" value=""></div>
            <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
          </div>
        </form>
      </div>
    </div>
    
    <footer class="footer">
      <div class="container">
        <div class="row">
          <div class="col-md-2">
            <div><span class="bold">Contact us: </span><a href="mailto:info@sentienceinstitute.org">info@sentienceinstitute.org</a></div>
            <div class="icons">
              <!-- <a href="/rss.xml"><i class="material-icons">rss_feed</i></a> -->
              <a href="https://www.facebook.com/sentienceinstitute"><img class="icon" src="../img/icons/icon_facebook_white.png"/></a>
              <a href="https://www.twitter.com/sentienceinst"><img class="icon" src="../img/icons/icon_twitter_white.png"/></a>
            </div>
          </div>
          <div class="col-md-10 last-column">
            <div>
              © 2017–2024 Sentience Institute
            </div>
            <div>
              <a href="/terms">Terms and Conditions &amp; Privacy Policy</a>
            </div>
            <div>
              Thank you, <a href="https://weanimals.org/">Jo-Anne McArthur</a>, for granting us the use of so many photos.
            </div>
          </div>
        </div>
      </div>
    </footer>
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/TweenMax.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js" integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn" crossorigin="anonymous"></script>
    <script src="/js/ready.js?v=@version@"></script>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-100318911-1', 'auto');
      ga('send', 'pageview');

    </script>
    
  </body>
</html>
