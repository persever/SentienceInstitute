<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

    <meta name="author" content="Sentience Institute" />

    <meta property="og:site_name" content="Sentience Institute" />
    <meta property="fb:app_id" content="302735083502826" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:site" content="@sentienceinst" />

    
    

    
    <meta property="description" content="We consider the terminology used to describe artificial entities and how this terminology may affect the moral consideration of artificial entities. Different combinations of terms variously emphasize the entity&#39;s role, material features, psychological features, and different research perspectives." />
    <meta property="og:description" content="We consider the terminology used to describe artificial entities and how this terminology may affect the moral consideration of artificial entities. Different combinations of terms variously emphasize the entity&#39;s role, material features, psychological features, and different research perspectives." />
    
    
    <title>Sentience Institute | The Terminology of Artificial Sentience</title>
    <meta property="title" content="The Terminology of Artificial Sentience" />
    <meta property="og:title" content="The Terminology of Artificial Sentience" />
    
    
    
    
    <meta property="og:url" content="http://www.sentienceinstitute.org/blog/artificial-sentience-terminology" />
    <meta property="og:image" content="http://www.sentienceinstitute.org/img/blog/20211122.png" />
    


    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico?v=1">
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,600" rel="stylesheet">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="../css/sentienceinstitute.css?v=2.0.1" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <link href="../css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <nav class="navbar navbar-inverse navbar-toggleable-sm fixed-top">
      <div class="container">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarText" aria-controls="navbarText" aria-expanded="false">
          <span class="navbar-toggler-icon"></span>
        </button>
        <a class="navbar-brand" href="/">
          <!-- <img class="nav-logo" src="../img/logo/SI_logo_white_200px.png"/> -->
          <img class="nav-logo-brandmark" src="../img/logo/SI_brandmark_white_heavier_web.png"/>
          <div class="nav-logo-text">
            <span>Sentience</span>
            <span class="nav-logo-text-institute">Institute</span>
          </div>
        </a>
        <div id="navbarText" class="collapse navbar-collapse">
          <ul class="navbar-nav">
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
                Research<span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
                <li><a href="/foundational-questions-summaries">Foundational Questions Summaries</a></li>
                <li><a href="/research">Reports</a></li>
                <li><a href="/research-agenda">Agenda</a></li>
                <!-- <li><a href="/press">Press Releases</a></li> -->
              </ul>
            </li>
            <li class="nav-item"><a class="nav-link" destination="/media">Media</a></li>
            <li class="nav-item"><a class="nav-link" destination="/podcast">Podcast</a></li>
            <li class="nav-item"><a class="nav-link" destination="/blog">Blog</a></li>
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
                About Us<span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
                <li><a href="/mission">Our Mission</a></li>
                <li><a href="/perspective">Our Perspective</a></li>
                <li><a href="/team">Our Team</a></li>
                <li class="nav-item"><a class="nav-link" href="/get-involved">Get Involved</a></li>
                <li><a href="/transparency">Transparency</a></li>
                <li><a href="/faq">FAQ</a></li>
              </ul>
            </li>
            <li class="nav-item nav-donate"><a class="nav-link" destination="/donate">Donate</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>
    




<div class="container image-container" img-id="20211122" style="background-image: url(/img/blog/20211122.png);">
  
</div>

<div class="container first-container gdoc-html-container blog-container artificial-sentience-terminology-container">
  <div class="title">
    The Terminology of Artificial Sentience
  </div>
  <div class="author-info">
    
    <div class="author">
      <div class="author-img"><img src="../img/team/janet.png"/></div>
      <div class="author-name-and-role">
      <div class="author-name">Janet Pauketat</div>
      <div class="author-role">Research Fellow</div>
    </div>
  </div>
  
  </div>
  <div class="date">
    November 22, 2021
  </div>
  <html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"></head><body class="c30"><p class="c17 c12"><span class="c8 c7">Edited by Jacy Reese Anthis and Ali Ladak. Many thanks to Thomas Moynihan, Tobias Baumann, and Teo Ajantaival for reviewing and providing feedback.</span></p><p class="c10"><span class="c7 c8"></span></p><p class="c17 c12"><span class="c28 c7">https://doi.org/1</span><span class="c7 c28">0.31234/osf.io/sujwf</span></p><h1 class="c22 c12" id="h.c8nnr2lymqdw"><span class="c5">Abstract</span></h1><p class="c12 c17"><span>We consider the terminology used to describe artificial entities and how this terminology may affect </span><span class="c11"><a class="c3" href="https://link.springer.com/article/10.1007/s11948-021-00331-8">the moral consideration of artificial entities</a></span><span>. Different combinations of terms variously emphasize the entity&#39;s role, material features</span><span>, </span><span>psychological features, and different research perspectives.</span><sup><a href="#ftnt1" id="ftnt_ref1">[1]</a></sup><span>&nbsp;The ideal term may vary across context, but we favor &ldquo;artificial sentience&rdquo; in general, in part because &ldquo;artificial&rdquo; is more common in relevant contexts than its near-synonyms, such as &ldquo;synthetic&rdquo; and &ldquo;digital,&rdquo; and to emphasize the </span><span class="c11"><a class="c3" href="https://www.sentienceinstitute.org/blog/the-importance-of-artificial-sentience">sentient artificial entities</a></span><span class="c0">&nbsp;who deserve moral consideration. The terms used to define and refer to these entities often take a human perspective by focusing on the benefits and drawbacks to humans. Evaluating the benefits and drawbacks of the terminology to the moral consideration of artificial entities may help to clarify emerging research, improve its impact, and align the interests of sentient artificial entities with the study of artificial intelligence (AI), especially research on AI ethics.</span></p><h1 class="c22 c12" id="h.nj85xrz4svye"><span class="c5">Table of Contents</span></h1><p class="c18 c12"><span class="c6"><a class="c3" href="#h.5bhjrdg9fnyw">The importance of conceptual clarity</a></span></p><p class="c18 c12"><span class="c6"><a class="c3" href="#h.pyjtf8okj61i">Terminology and conceptual definitions</a></span></p><p class="c27 c12"><span class="c6"><a class="c3" href="#h.ikewjbl87wn2">Table 1: Terminology defining an entity&rsquo;s role</a></span></p><p class="c27 c12"><span class="c6"><a class="c3" href="#h.icdiftajrsiq">Table 2: Terminology defining material features</a></span></p><p class="c27 c12"><span class="c6"><a class="c3" href="#h.cmci3dfe2ck0">Table 3: Terminology defining psychological features</a></span></p><p class="c27 c12"><span class="c6"><a class="c3" href="#h.kxo3d2vpqh52">Table 4: Consequential combinations of features and role</a></span></p><p class="c18 c12"><span class="c6"><a class="c3" href="#h.q0xhbhrjbcrr">What term should we use?</a></span></p><p class="c27 c12"><span class="c6"><a class="c3" href="#h.wd70rlsamahb">Reasons for &ldquo;artificial sentience&rdquo;</a></span></p><p class="c27 c12"><span class="c6"><a class="c3" href="#h.mfgx3trc14zo">Reasons against &ldquo;artificial sentience&rdquo;</a></span></p><p class="c12 c27"><span class="c6"><a class="c3" href="#h.qh0wokkfwsiq">Using multiple terms</a></span></p><p class="c12 c18"><span class="c6"><a class="c3" href="#h.olf2eqrzowjq">Appendix: Terminology defining relevant fields of study</a></span></p><p class="c12 c14"><span class="c6"><a class="c3" href="#h.68p7s91zatvy">Table A1: Fields of Study</a></span></p><h1 class="c22 c12" id="h.5bhjrdg9fnyw"><span class="c5">The importance of conceptual clarity</span></h1><p class="c17 c12"><span class="c0">Sentience Institute uses the term &ldquo;artificial sentience&rdquo; to describe artificial entities with the capacity for positive and negative experiences. When we survey the public, we use the terms &ldquo;artificial beings&rdquo; and &ldquo;robots/AIs&rdquo; to refer to &ldquo;intelligent entities built by humans, such as robots, virtual copies of human brains, or computer programs that solve problems, with or without a physical body, that may exist now or in the future.&rdquo; We have also used the terms &ldquo;artificial intelligences&rdquo; and &ldquo;artificial entities.&rdquo; These five terms are just a few of the many used in the design, development, and scholarship of AI.</span></p><p class="c10"><span class="c0"></span></p><p class="c17 c12"><span>When a term t</span><span>hat expresses a concept is ambiguous, </span><span>it becomes difficult to disentangle the theoretical connotation intended by the researchers and the meaning of participants&rsquo; responses in empirical studies. This reduces the impact of empirical research, especially for concepts that are tied to ordinary language like &ldquo;artificial.&rdquo;</span><sup><a href="#ftnt2" id="ftnt_ref2">[2]</a></sup><span>&nbsp;Researchers may assume that everyone shares their same definitions when in fact they are fuzzy concepts, &ldquo;[that] possess two or more alternative meanings and thus cannot be reliably identified or applied by different readers or scholars&rdquo; (</span><span class="c11"><a class="c3" href="https://www.tandfonline.com/doi/abs/10.1080/0034340032000108796">Markusen, 2003</a></span><span class="c0">, p. 702). Markusen argues that this can decrease scholars&rsquo; belief in the need for empirical tests, can lead to the devaluation of empirical evidence, and can reduce the credibility of research.</span></p><p class="c10"><span class="c0"></span></p><p class="c17 c12"><span>Conceptual ambiguity can lead to </span><span class="c11"><a class="c3" href="https://www.tandfonline.com/doi/abs/10.1080/1047840X.2016.1082418">concept creep</a></span><span>,</span><span>&nbsp;when a concept becomes so broad and deep that non-examples are difficult to find. </span><span>The methodological and real-world implications of conceptual ambiguity range from reduced trustworthiness of the research to the detachment of scholarship from policy-making and advocacy. For instance, a policy-maker is more likely to avoid &ldquo;fuzzy concepts&rdquo; when implementing policies because there are no clear definitions that can be used to structure their policy. That is, &ldquo;fuzzy concepts&rdquo; provide fuzzy guidance on how a policy will affect systemic power distributions, legal structures, and the actions of different people (e.g., advocates, politicians, lay people).</span></p><p class="c10"><span class="c0"></span></p><p class="c17 c12"><span>In the following sections, we attempt to include as many of the terms as we could find relevant to the interdisciplinary study of artificial entities&rsquo; moral, social, and mental capacities.</span><sup><a href="#ftnt3" id="ftnt_ref3">[3]</a></sup><span class="c0">&nbsp;</span></p><p class="c10"><span class="c0"></span></p><p class="c17 c12"><span class="c19 c7">Note. We loosely group terms into four categories although several terms could belong to other categories. </span></p><h1 class="c12 c22" id="h.pyjtf8okj61i"><span class="c5">Terminology and conceptual definitions</span></h1><p class="c17 c12"><span class="c0">The first set of terms elicits a mental image of an entity&rsquo;s role in the world. These terms are most frequently used as nouns that can be modified with information about their material or psychological features, although some, like &ldquo;super&rdquo; and &ldquo;transformative,&rdquo; typically serve as adjectives. &ldquo;Machine&rdquo; is used as a noun with feature modifiers (e.g., &ldquo;digital machine,&rdquo; &ldquo;autonomous machine&rdquo;). However, it is also sometimes used as a feature-like modifier of other features (e.g., &ldquo;machine intelligence&rdquo;). Below are terms defining an entity&rsquo;s role. </span></p><h4 class="c12 c26" id="h.ikewjbl87wn2"><span class="c7">Table 1:</span><span class="c24">&nbsp;Terminology defining an entity&rsquo;s role</span></h4><iframe src="https://docs.google.com/spreadsheets/d/e/2PACX-1vR18_wPdaUaf14TMq_J2avf7quI1nK_RrDftpaBSa04ResU2EPf5Bx6pCgw_ZWYPkAOz30kl0OU0k4o/pubhtml?gid=0&amp;range=a1:e15&amp;single=true&amp;widget=false&amp;headers=false&amp;chrome=false" width="100%" height="800"></iframe><p class="c10"><span class="c0"></span></p><p class="c17 c12"><span class="c0">The second set of terms evokes a mental image of an artificial entity&rsquo;s material structure. These terms focus either on what the entity is made from or how they exist. They often modify terms defining an entity&rsquo;s role (e.g., &ldquo;artificial agent&rdquo;). Below are terms defining material features.</span></p><h4 class="c26 c12" id="h.icdiftajrsiq"><span class="c7">Table 2:</span><span>&nbsp;</span><span class="c24">&nbsp;Terminology defining material features</span></h4><iframe src="https://docs.google.com/spreadsheets/d/e/2PACX-1vR18_wPdaUaf14TMq_J2avf7quI1nK_RrDftpaBSa04ResU2EPf5Bx6pCgw_ZWYPkAOz30kl0OU0k4o/pubhtml?gid=374511274&amp;range=a1:e9&amp;single=true&amp;widget=false&amp;headers=false&amp;chrome=false" width="100%" height="800"></iframe><p class="c10"><span class="c0"></span></p><p class="c17 c12"><span class="c0">A third set of terms defines the psychological features of an entity. These terms operationalize abstract and indirectly observable mental phenomena (e.g., intelligence, friendliness). Psychological features are inferred from observing complex criteria agreed upon by experts. For example, we cannot observe &ldquo;autonomy&rdquo; directly. We infer &ldquo;autonomy&rdquo; from introspection (i.e., self-reports) and behavior. These terms differ from material features because material features can be directly observed. Below are terms defining psychological features.</span></p><h4 class="c26 c12" id="h.cmci3dfe2ck0"><span class="c7">Table 3:</span><span class="c24">&nbsp;Terminology defining psychological features</span></h4><iframe src="https://docs.google.com/spreadsheets/d/e/2PACX-1vR18_wPdaUaf14TMq_J2avf7quI1nK_RrDftpaBSa04ResU2EPf5Bx6pCgw_ZWYPkAOz30kl0OU0k4o/pubhtml?gid=1073971666&amp;range=a1:e12&amp;single=true&amp;widget=false&amp;headers=false&amp;chrome=false" width="100%" height="800"></iframe><p class="c10"><span class="c0"></span></p><p class="c17 c12"><span>Combinations of feature and role terms have been used within and across many fields of study</span><sup><a href="#ftnt4" id="ftnt_ref4">[4]</a></sup><span>&nbsp;to describe artificial entities. For instance, &ldquo;</span><span class="c11"><a class="c3" href="https://link.springer.com/article/10.1007/s10676-020-09556-w">friendly AI</a></span><span>&rdquo; has been used to describe AIs who mimic human friendliness and are benign to humans. &ldquo;</span><span class="c11"><a class="c3" href="https://www.nature.com/articles/s41586-018-0637-6.">Moral machine</a></span><span class="c0">&rdquo; has been used to describe machines that make ethical decisions or need to solve moral dilemmas, like self-driving cars. Some of these combinations are more widely used and well-known. Other combinations have stronger implications for taking moral action and receiving moral consideration. Many combinations are used only in specific contexts, based on convenience, or merely as placeholders. Below we outline some combinations that we think are consequential and related to the moral consideration of artificial entities.</span></p><h4 class="c26 c12" id="h.kxo3d2vpqh52"><span class="c7">Table 4:</span><span class="c24">&nbsp;Consequential combinations of features and role</span></h4><iframe src="https://docs.google.com/spreadsheets/d/e/2PACX-1vR18_wPdaUaf14TMq_J2avf7quI1nK_RrDftpaBSa04ResU2EPf5Bx6pCgw_ZWYPkAOz30kl0OU0k4o/pubhtml?gid=1950794443&amp;range=a1:e12&amp;single=true&amp;widget=false&amp;headers=false&amp;chrome=false" width="100%" height="800"></iframe><h1 class="c9" id="h.q0xhbhrjbcrr"><span class="c5">What term should we use?</span></h1><p class="c4"><span>Is the same terminology useful for the general public, engineers, scientists, ethicists, lawyers, and policy-makers? There&rsquo;s </span><span class="c11"><a class="c3" href="https://dl.acm.org/doi/abs/10.1145/3434074.3446911">some suggestion</a></span><span>&nbsp;that the general public and experts differ in their understanding of artificial entities and support for their rights. Would a common, consensual terminology enable more effective interdisciplinary research, policy-making, and advocacy? If having an </span><span class="c11"><a class="c3" href="https://intelligence.org/2013/06/19/what-is-intelligence-2/">imprecise definition</a></span><span class="c0">&nbsp;is preferred, how can differences in terminology be reconciled to maximize the clarity and utility of the terms?</span></p><p class="c1"><span class="c0"></span></p><p class="c4"><span class="c0">Whether or not terms generalize across contexts might matter. Should we use terminology that can be applied to humans, nonhuman animals, algorithms, and machines? Is it necessary to specify an entity&rsquo;s role? Several of the consequential combinations do not (e.g., &ldquo;artificial general intelligence,&rdquo; &ldquo;artificial sentience&rdquo;). Does the psychological feature need to be narrow or broad? &ldquo;Consciousness&rdquo; is broad, but it is also &ldquo;fuzzy&rdquo; because of the many conceptualizations in current usage. On the other hand, a narrow term like &ldquo;friendly&rdquo; only applies to one aspect of an entity&rsquo;s behavior and may not retain meaning over time and across context.</span></p><p class="c1"><span class="c0"></span></p><p class="c4"><span class="c0">Below we explain our preference for &ldquo;artificial sentience,&rdquo; consider some possible reasons not to use &ldquo;artificial sentience,&rdquo; and consider using multiple terms.</span></p><h2 class="c21" id="h.wd70rlsamahb"><span>Reasons for &ldquo;artificial sentience</span><span class="c15">&rdquo;</span></h2><p class="c4"><span>We favor the term &ldquo;artificial sentience&rdquo; for the following </span><span class="c23">linguistic </span><span class="c0">reasons:</span></p><p class="c1"><span class="c0"></span></p><ul class="c20 lst-kix_os1ya0pym7px-0 start"><li class="c2 li-bullet-0"><span class="c0">&ldquo;Artificial sentience&rdquo; sits in a &ldquo;Goldilocks Zone&rdquo; of broad and narrow terminology. &ldquo;Artificial&rdquo; is inclusive of many entities and distinguishes entities composed at least partly of non-biological substrates from completely biological entities. &ldquo;Artificial&rdquo; is commonly used and understood in relevant contexts. &ldquo;Sentience&rdquo; is an aspect of &ldquo;mind&rdquo; that can be differentiated from broad and narrow psychological features such as &ldquo;mind&rdquo; and &ldquo;intelligence,&rdquo; respectively.</span></li><li class="c2 li-bullet-0"><span>&ldquo;Artificial sentience,&rdquo; as a newer term, does not have divergent meanings across time and field of study like the dual meanings that exist for some terms (e.g., &ldquo;digital mind&rdquo;). </span><span class="c11"><a class="c3" href="https://mitpress.mit.edu/books/digital-mind">Scholars</a></span><span>&nbsp;concerned with the</span><span class="c11"><a class="c3" href="https://oxford.universitypressscholarship.com/view/10.1093/oso/9780192894076.001.0001/oso-9780192894076-chapter-18">&nbsp;effects of AIs on human society</a></span><span>&nbsp;have used &ldquo;digital mind&rdquo; to refer to </span><span class="c11"><a class="c3" href="https://www.worldscientific.com/doi/10.1142/S1793843012400161">psychological minds that exist purely on a computer</a></span><span>&nbsp;or in a digital space. The term is also </span><span class="c11"><a class="c3" href="https://www.learntechlib.org/primary/p/14684/">associated</a></span><span>&nbsp;with human brains and </span><span class="c11"><a class="c3" href="https://www.taylorfrancis.com/books/mono/10.4324/9780203156803/education-networks-joel-spring">the dynamics of digital technologies</a></span><span class="c0">. In this context, a &ldquo;digital mind&rdquo; is a human brain on digital media. </span></li><li class="c2 li-bullet-0"><span class="c0">&ldquo;Artificial sentience&rdquo; uses similar language to &ldquo;artificial intelligence&rdquo; and is likely to be conceptually associated with it. &ldquo;Artificial intelligence&rdquo; has a well-established meaning and is commonly used by the general public and experts. We believe that similarity to the well-known &ldquo;artificial intelligence&rdquo; will enable experts and the public alike to grasp the meaning of &ldquo;artificial sentience&rdquo; as an &ldquo;experiential&rdquo; extension of &ldquo;artificial intelligence.&rdquo; </span></li><li class="c2 li-bullet-0"><span class="c0">There is little reason to expect the term &ldquo;artificial sentience&rdquo; to be associated with God-like terms such as &ldquo;machine superintelligence&rdquo; that reduce moral consideration by dint of being too threatening or tool-like terms such as &ldquo;smart device&rdquo; that prompt instrumental mental images. The common conception of artificial entities as technological tools may limit the extent to which they are morally considered and overcoming these associations with existing terminology may be difficult.</span></li></ul><p class="c1"><span class="c0"></span></p><p class="c4"><span>We favor the term &ldquo;artificial sentience&rdquo; for the following </span><span class="c23">conceptual </span><span class="c0">reasons:</span></p><p class="c1"><span class="c0"></span></p><ul class="c20 lst-kix_os1ya0pym7px-0"><li class="c2 li-bullet-0"><span>&ldquo;Artificial sentience&rdquo; avoids some of the conceptual difficulties associated with &ldquo;artificial consciousness.&rdquo; </span><span class="c11"><a class="c3" href="https://plato.stanford.edu/entries/materialism-eliminative/">Some stances within philosophy</a></span><span>, including a </span><span class="c11"><a class="c3" href="https://www.sentienceinstitute.org/blog/what-is-sentience">position held at SI</a></span><span class="c0">, argue that the construct of &ldquo;consciousness&rdquo; and some of its underlying mental circuitry (e.g., how introspection arises from neural and cognitive systems) are particularly ill-defined and difficult to observe.</span></li><li class="c2 li-bullet-0"><span class="c0">&ldquo;Artificial sentience&rdquo; is inclusive of entirely non-biological entities, hybrid biological and non-biological entities, and artificial entities originating from evolutionarily biological processes like whole brain emulations. This inclusivity may increase the tractability of advocating for the moral consideration of artificial entities in a way that terms like &ldquo;non-biological sentience&rdquo; may not.</span></li><li class="c2 li-bullet-0"><span>The term &ldquo;artificial sentience&rdquo; prioritizes &ldquo;sentience,&rdquo; an affective capacity, as the key distinguishing aspect of mind critical to experiential capacities like motivation and affect. Although &ldquo;</span><span class="c11"><a class="c3" href="https://dictionary.apa.org/mind">mind</a></span><span>&rdquo; encompasses all mental capacities, it is sometimes used to signify only cognition, reasoning, and rationality. This usage of &ldquo;mind&rdquo; is often implicitly considered &ldquo;cold,&rdquo; controlled, and unemotional, which can lead to mechanistic forms of </span><span class="c11"><a class="c3" href="https://www.annualreviews.org/doi/abs/10.1146/annurev-psych-010213-115045">dehumanization</a></span><span class="c0">&nbsp;and moral circle exclusion.</span></li><li class="c2 li-bullet-0"><span class="c0">&ldquo;Sentience&rdquo; requires features related to having affective experiences (e.g., the capacity to have positive and negative experiences). This definition may make &ldquo;sentience&rdquo; less subject to &ldquo;fuzziness&rdquo; than other psychological features that are difficult to define and observe like &ldquo;qualia.&rdquo; </span></li><li class="c2 li-bullet-0"><span>&ldquo;Artificial sentience&rdquo; may be less </span><span class="c11"><a class="c3" href="https://psycnet.apa.org/record/2008-09974-003">threatening</a></span><span class="c0">&nbsp;to people than terms like &ldquo;super-beneficiary,&rdquo; &ldquo;digital mind,&rdquo; or &ldquo;artificial consciousness.&rdquo; &ldquo;Super-beneficiary&rdquo; may prompt realistic threats over resource sharing. &ldquo;Digital mind&rdquo; and &ldquo;artificial consciousness&rdquo; may prompt symbolic threats to human distinctiveness because of the association of &ldquo;consciousness&rdquo; and &ldquo;mind&rdquo; with humans&rsquo; sophisticated mental capacities. &ldquo;Artificial sentience&rdquo; may be less threatening because &ldquo;sentience&rdquo; is not unique to humans and because &ldquo;sentience&rdquo; does not necessarily imply sharing resources or social status.</span></li></ul><p class="c1 c29"><span class="c0"></span></p><p class="c4"><span>We favor the term &ldquo;artificial sentience&rdquo; for the following </span><span class="c23">moral </span><span class="c0">reasons:</span></p><p class="c1"><span class="c0"></span></p><ul class="c20 lst-kix_os1ya0pym7px-0"><li class="c2 li-bullet-0"><span>&ldquo;Artificial sentience&rdquo; connotes the aspect of artificial entities&rsquo; minds that we believe is critical to moral consideration. Affective components of mind like sentience are linked to increased moral consideration. Cognitive components of mind like memory are typically associated with the capacity to take moral action.</span><sup><a href="#ftnt5" id="ftnt_ref5">[5]</a></sup><span class="c0">&nbsp;We believe that this may be an important distinction for moral consideration given the potential need to distinguish between future &ldquo;digital minds&rdquo; who have some degree of sentience and &ldquo;digital minds&rdquo; that are cognitively sophisticated but devoid of experiential capacities.</span></li><li class="c2 li-bullet-0"><span>&ldquo;Sentience&rdquo; is the psychological feature most clearly related to the moral consideration of nonhumans. Specifically, &ldquo;sentience&rdquo; has a clear track record in nonhuman animal welfare science and advocacy for moral consideration and has some </span><span class="c11"><a class="c3" href="https://link.springer.com/article/10.1007%252Fs00146-021-01179-z">backing</a></span><span>&nbsp;within AI ethics. &ldquo;Consciousness&rdquo; has a more </span><span class="c11"><a class="c3" href="https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780198749677.001.0001/oxfordhb-9780198749677-e-30">convoluted relationship</a></span><span class="c0">&nbsp;with moral consideration.</span></li><li class="c2 li-bullet-0"><span class="c0">There are clear consequences of sentience dismissal for humans (e.g., the Atlantic slave trade) and nonhumans (e.g., factory farming). The capacity to suffer is denied with sentience dismissal, facilitating exclusion from the moral circle. &ldquo;Artificial sentience&rdquo; is likely to be critical for recognizing the moral status of sentient artificial entities in a way that consequential combinations like &ldquo;artificial consciousness&rdquo; are not. </span></li></ul><h2 class="c21" id="h.mfgx3trc14zo"><span class="c15">Reasons against &ldquo;artificial sentience&rdquo;</span></h2><ul class="c20 lst-kix_4anglzpfd58s-0 start"><li class="c2 c12 li-bullet-0"><span class="c0">The use of &ldquo;artificial&rdquo; may lead to some associations with &ldquo;fakeness&rdquo; or &ldquo;unnaturalness.&rdquo; This could be a concern if it leads to the dismissal of artificial entities&rsquo; capacity to have so-called &ldquo;real&rdquo; experiences.</span></li><li class="c2 c12 li-bullet-0"><span>&ldquo;Artificial sentience&rdquo; may be more threatening than terms like &ldquo;non-biological sentience&rdquo;</span><sup><a href="#ftnt6" id="ftnt_ref6">[6]</a></sup><span class="c0">&nbsp;if people associate &ldquo;artificial&rdquo; with being constructed in a laboratory for nefarious purposes or if they associate &ldquo;artificial intelligence&rdquo; with dangers outside of human control.</span></li><li class="c2 c12 li-bullet-0"><span>The use of &ldquo;sentience&rdquo; is sometimes conflated with &ldquo;</span><span class="c11"><a class="c3" href="https://mahb.stanford.edu/library-item/theory-sapience-using-systems-science-understand-nature-wisdom-human-mind/">sapience</a></span><span class="c0">,&rdquo; or conceptions of exaggerated intelligence, wisdom, and reasoning. This could be a concern for promoting understandings of what artificial sentience entails.</span></li><li class="c2 c12 li-bullet-0"><span class="c0">&ldquo;Artificial sentience&rdquo; is new and unfamiliar to the general public and many experts. This could lead to some initial confusion. The longevity of the term could also be questioned. Given that it is new, we cannot yet know whether or not it will endure meaningfully into the future.</span></li><li class="c2 c12 li-bullet-0"><span class="c0">&ldquo;Artificial sentience&rdquo; has some philosophical overlap with &ldquo;artificial consciousness&rdquo; that may increase confusion over the meaning of the term when used in interdisciplinary or transdisciplinary contexts. This overlap may also mean that some critiques of &ldquo;artificial consciousness&rdquo; may apply to conceptions of &ldquo;artificial sentience&rdquo; that are too broadly defined (e.g., broader than the capacity for positive and negative experiences).</span></li><li class="c2 c12 li-bullet-0"><span class="c0">The connection between &ldquo;artificial intelligence&rdquo; and &ldquo;artificial sentience&rdquo; might create a spillover of hype from AI. Ungrounded excitement could prompt increased efforts to develop artificial sentience without enough forethought and preparation for a world with sentient artificial entities who may or may not receive moral consideration.</span></li><li class="c2 li-bullet-0"><span>&ldquo;Artificial sentience&rdquo; is likely to require evidence of the presence of a number of relevant features (e.g., those related to detecting harmful stimuli, behavioral avoidance, centralized information processing) that may enable us to make judgments about the likelihood and degree of sentience. This could enable a probabilistic approach for operationalizing &ldquo;artificial sentience&rdquo; that might increase our chances of correctly judging whether an artificial entity is sentient (advancing the moral consideration of artificial entities). However, having to calculate the probability of artificial sentience may make it easier for some to dismiss the existence of &ldquo;artificial sentience&rdquo; given that it may reduce confidence in the concept by providing </span><span class="c11"><a class="c3" href="https://royalsocietypublishing.org/doi/10.1098/rspa.2015.0748">too much evidence</a></span><span class="c0">. </span></li></ul><h2 class="c21" id="h.qh0wokkfwsiq"><span class="c15">Using multiple terms</span></h2><p class="c4"><span class="c0">The best strategy might be to use multiple terms to represent the interests of algorithmically-based, at least partly non-biological entities, of which artificial sentience (AS) may eventually be considered an umbrella term. Below is a possible initial taxonomy of terms based on their relationship to the moral referents of patiency and agency and to the specificity of the term. </span></p><p class="c1"><span class="c0"></span></p><p class="c4"><span class="c7">Figure 1:</span><span class="c0">&nbsp;Possible Taxonomy of Terms</span></p><p class="c1"><span class="c0"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px*1.5; height: 400.00px*1.5;"><img alt="" src="images/artificial-sentience-terminology/image1.png" style="width: 624.00px*1.5; height: 400.00px*1.5; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span class="c7 c19">Note. Terms are positioned along two (of many possible) dimensions. Moral references are on the x-axis and specificity is along the y-axis. These locations are imprecise as they reflect cultural and intellectual associations that are likely to vary across readers and change over time.</span></p><p class="c1"><span class="c0"></span></p><p class="c4"><span class="c0">Possible Uses for Specific Terms:</span></p><p class="c1"><span class="c0"></span></p><ul class="c20 lst-kix_ne4qb14lxeh7-0 start"><li class="c2 li-bullet-0"><span class="c0">&ldquo;Sentient artificial being&rdquo; and &ldquo;sentient artificial entity&rdquo; are likely to be useful for communicating about individual AIs with non-experts or in discussions where the emphasis is on sentience rather than intelligence.</span></li><li class="c2 li-bullet-0"><span class="c0">&ldquo;Sentient artificial intelligence&rdquo; (&ldquo;sentient AI&rdquo;) is likely to be useful for communicating with experts and non-experts about individual AIs with some degree of sentience or the capacity for sentience in AI.</span></li><li class="c2 li-bullet-0"><span>&ldquo;</span><span class="c11"><a class="c3" href="https://oxford.universitypressscholarship.com/view/10.1093/oso/9780192894076.001.0001/oso-9780192894076-chapter-18">Digital mind</a></span><span class="c0">&rdquo; is likely to be useful for emphasizing internal, algorithmic mental capacities rather than substrate-based material structures. </span></li><li class="c2 li-bullet-0"><span>&ldquo;</span><span class="c11"><a class="c3" href="https://forum.effectivealtruism.org/tag/digital-person">Digital people</a></span><span>&rdquo;</span><sup><a href="#ftnt7" id="ftnt_ref7">[7]</a></sup><span class="c0">&nbsp;is likely to be useful when referring to the digital nature of human descendants and the sorts of societies they may live in.</span></li></ul><h1 class="c22 c12" id="h.olf2eqrzowjq"><span>Appendix: </span><span>Terminology defining relevant fields of study</span></h1><p class="c17 c12"><span class="c0">Some terms define the academic fields of study surrounding artificial entities. The fields described below seem likely to have the greatest impact on long-term outcomes of artificial entity development such as how they will be designed and the resulting ethical implications.</span></p><h4 class="c26 c12" id="h.68p7s91zatvy"><span class="c7">Table A1: </span><span class="c24">Fields of Study</span></h4><iframe src="https://docs.google.com/spreadsheets/d/e/2PACX-1vR18_wPdaUaf14TMq_J2avf7quI1nK_RrDftpaBSa04ResU2EPf5Bx6pCgw_ZWYPkAOz30kl0OU0k4o/pubhtml?gid=1950794443&amp;range=a1:e12&amp;single=true&amp;widget=false&amp;headers=false&amp;chrome=false" width="100%" height="800"></iframe><p class="c10"><span class="c0"></span></p><p class="c10"><span class="c0"></span></p><p class="c10"><span class="c5"></span></p><hr class="c25"><div><p class="c4 c12"><a href="#ftnt_ref1" id="ftnt1">[1]</a><span class="c16 c13">&nbsp;We consider terms and their connotations in the English language. The usage and meaning of some terms is likely to be different in other languages, a topic that requires future study. Linguistic differences may have global implications for the moral consideration of artificial entities that have yet to be examined.</span></p></div><div><p class="c4 c12"><a href="#ftnt_ref2" id="ftnt2">[2]</a><span class="c13">&nbsp;</span><span class="c11 c13"><a class="c3" href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-5914.1978.tb00400.x">Blascovich and Ginsburg (1978)</a></span><span class="c16 c13">&nbsp;discuss conceptual ambiguity in regards to the social psychological study of &ldquo;risk-taking.&rdquo;</span></p></div><div><p class="c4 c12"><a href="#ftnt_ref3" id="ftnt3">[3]</a><span class="c13 c16">&nbsp;See the Appendix for a list of terms defining relevant fields of study.</span></p></div><div><p class="c4 c12"><a href="#ftnt_ref4" id="ftnt4">[4]</a><span class="c16 c13">&nbsp;See the Appendix for a list of terms defining relevant fields of study.</span></p></div><div><p class="c4 c12"><a href="#ftnt_ref5" id="ftnt5">[5]</a><span class="c13">&nbsp;Summarizing from </span><span class="c11 c13"><a class="c3" href="https://science.sciencemag.org/content/315/5812/619.full">Gray et al. (2007)</a></span><span class="c13">&nbsp;and </span><span class="c11 c13"><a class="c3" href="https://www.tandfonline.com/doi/full/10.1080/1047840X.2012.651387">Gray et al. (2012)</a></span><span class="c13">.</span><span class="c16 c13">&nbsp;</span></p></div><div><p class="c4 c12"><a href="#ftnt_ref6" id="ftnt6">[6]</a><span class="c16 c13">&nbsp;A term like &ldquo;non-biological sentience&rdquo; might contrast better with &ldquo;biological sentience,&rdquo; increasing the focus on &ldquo;sentience&rdquo; rather than on the entity&rsquo;s material features and substrate (i.e., whether they are a human, a nonhuman animal, algorithm, or machine). Reducing the emphasis on substrate may facilitate attempts to increase the moral consideration of artificial entities.</span></p></div><div><p class="c4 c12"><a href="#ftnt_ref7" id="ftnt7">[7]</a><span class="c13">&nbsp;See Holden Karnofsky&rsquo;s </span><span class="c11 c13"><a class="c3" href="https://www.cold-takes.com/how-digital-people-could-change-the-world/">Cold Takes blog</a></span><span class="c16 c13">&nbsp;for more on &ldquo;digital people.&rdquo;</span></p></div></body></html>
</div>




    <hr>
    <div class="container newsletter-container ">
      <p>Subscribe to our newsletter to receive updates on our research and activities. We average one to two emails per year.</p>
      <div id="mc_embed_signup">
        <form action="//sentienceinstitute.us15.list-manage.com/subscribe/post?u=d898f823d035e0601866e68d6&amp;id=cbf2d915a6" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
          <div id="mc_embed_signup_scroll">
            <input type="email" value="" name="EMAIL" class="email form-input" id="mce-EMAIL" placeholder="Email address" required>
            <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
            <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_d898f823d035e0601866e68d6_cbf2d915a6" tabindex="-1" value=""></div>
            <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
          </div>
        </form>
      </div>
    </div>
    
    <footer class="footer">
      <div class="container">
        <div class="row">
          <div class="col-md-2">
            <div><span class="bold">Contact us: </span><a href="mailto:info@sentienceinstitute.org">info@sentienceinstitute.org</a></div>
            <div class="icons">
              <!-- <a href="/rss.xml"><i class="material-icons">rss_feed</i></a> -->
              <a href="https://www.facebook.com/sentienceinstitute"><img class="icon" src="../img/icons/icon_facebook_white.png"/></a>
              <a href="https://www.twitter.com/sentienceinst"><img class="icon" src="../img/icons/icon_twitter_white.png"/></a>
            </div>
          </div>
          <div class="col-md-10 last-column">
            <div>
              Â© 2018 Sentience Institute
            </div>
            <div>
              <a href="/terms">Terms and Conditions &amp; Privacy Policy</a>
            </div>
            <div>
              Thank you, <a href="https://weanimals.org/">Jo-Anne McArthur</a>, for granting us the use of so many photos.
            </div>
          </div>
        </div>
      </div>
    </footer>
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/TweenMax.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js" integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn" crossorigin="anonymous"></script>
    <script src="/js/ready.js?v=@version@"></script>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-100318911-1', 'auto');
      ga('send', 'pageview');

    </script>
    
  </body>
</html>
