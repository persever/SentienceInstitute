<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

    <meta name="author" content="Sentience Institute" />

    <meta property="og:site_name" content="Sentience Institute" />
    <meta property="fb:app_id" content="302735083502826" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:site" content="@sentienceinst" />

    
    

    
    <meta property="description" content="Work to protect the interests of artificial sentience (AS advocacy) could be very important. It could improve the lives of vast numbers of future beings and be among the most cost-effective actions we could possibly take at the present time to help others." />
    <meta property="og:description" content="Work to protect the interests of artificial sentience (AS advocacy) could be very important. It could improve the lives of vast numbers of future beings and be among the most cost-effective actions we could possibly take at the present time to help others." />
    
    
    <title>Sentience Institute | Prioritization Questions for Artificial Sentience</title>
    <meta property="title" content="Prioritization Questions for Artificial Sentience" />
    <meta property="og:title" content="Prioritization Questions for Artificial Sentience" />
    
    
    
    
    <meta property="og:url" content="http://www.sentienceinstitute.org/blog/prioritization-questions-for-artificial-sentience" />
    <meta property="og:image" content="http://www.sentienceinstitute.org/img/blog/20211015.png" />
    


    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico?v=1">
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,600" rel="stylesheet">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="../css/sentienceinstitute.css?v=2.0.1" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <link href="../css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <nav class="navbar navbar-inverse navbar-toggleable-sm fixed-top">
      <div class="container">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarText" aria-controls="navbarText" aria-expanded="false">
          <span class="navbar-toggler-icon"></span>
        </button>
        <a class="navbar-brand" href="/">
          <!-- <img class="nav-logo" src="../img/logo/SI_logo_white_200px.png"/> -->
          <img class="nav-logo-brandmark" src="../img/logo/SI_brandmark_white_heavier_web.png"/>
          <div class="nav-logo-text">
            <span>Sentience</span>
            <span class="nav-logo-text-institute">Institute</span>
          </div>
        </a>
        <div id="navbarText" class="collapse navbar-collapse">
          <ul class="navbar-nav">
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
                Research<span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
                <li><a href="/research-agenda">Agenda</a></li>
                <li><a href="/foundational-questions-summaries">Foundational Questions for Animal Advocacy</a></li>
                <li><a href="/research">Reports</a></li>
                <li><a href="/aims-survey">Artificial Intelligence, Morality, and Sentience (AIMS) Survey</a></li>
                <li><a href="/aft-survey">Animals, Food, and Technology (AFT) Survey</a></li>
                <!-- <li><a href="/press">Press Releases</a></li> -->
              </ul>
            </li>
            <li class="nav-item"><a class="nav-link" destination="/media">Media</a></li>
            <li class="nav-item"><a class="nav-link" destination="/podcast">Podcast</a></li>
            <li class="nav-item"><a class="nav-link" destination="/blog">Blog</a></li>
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
                About Us<span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
                <!-- <li><a href="/mission">Our Mission</a></li> -->
                <li><a href="/perspective">Our Perspective</a></li>
                <li><a href="/team">Our Team</a></li>
                <li class="nav-item"><a class="nav-link" href="/get-involved">Get Involved</a></li>
                <li><a href="/transparency">Transparency</a></li>
                <!-- <li><a href="/faq">FAQ</a></li> -->
              </ul>
            </li>
            <li class="nav-item nav-donate"><a class="nav-link" destination="/donate">Donate</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>
    




<div class="container image-container" img-id="20211015" style="background-image: url(/img/blog/20211015.png);">
  
</div>

<div class="container first-container gdoc-html-container blog-container prioritization-questions-for-artificial-sentience-container">
  <div class="title">
    Prioritization Questions for Artificial Sentience
  </div>
  <div class="author-info">
    
    <div class="author">
      <div class="author-img"><img src="../img/team/jamie.png"/></div>
      <div class="author-name-and-role">
      <div class="author-name">Jamie Harris</div>
      <div class="author-role">Researcher</div>
    </div>
  </div>
  
  </div>
  <div class="date">
    October 15, 2021
  </div>
  <html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"></head><body class="c1 c17"><p class="c0"><span class="c1 c10">Many thanks to Janet Pauketat, Ali Ladak, Jacy Reese Anthis, Robert Long, Leonie K&ouml;&szlig;ler, and Michael Aird for reviewing and providing feedback.</span></p><h1 class="c13" id="h.z31f24n5a4b"><span>Introduction</span></h1><p class="c0"><span class="c1">Work to protect</span><span class="c1">&nbsp;the interests of artificial sentience</span><span class="c1">&nbsp;(AS advocacy</span><sup class="c1"><a href="#ftnt1" id="ftnt_ref1">[1]</a></sup><span class="c1">) </span><span class="c1">could be </span><span class="c2 c1"><a class="c3" href="https://www.sentienceinstitute.org/blog/the-importance-of-artificial-sentience">very important</a></span><span class="c1">. It could improve the lives of vast numbers of future beings and be among the most </span><span class="c1">cost-effective actions</span><span class="c1">&nbsp;we could possibly take at the present time to help others.</span><sup class="c1"><a href="#ftnt2" id="ftnt_ref2">[2]</a></sup><span class="c1">&nbsp;But this is uncertain: it is subject to many &ldquo;crucial considerations.&rdquo; </span><span class="c2 c1"><a class="c3" href="http://www.stafforini.com/blog/bostrom/">Bostrom (2014a)</a></span><span class="c6 c1">&nbsp;defined a crucial consideration:</span></p><p class="c0 c12"><span class="c6 c1"></span></p><p class="c0 c16"><span class="c1">A consideration such that if it were taken into account it would overturn the conclusions we would otherwise reach about how we should direct our efforts, or an idea or argument that might possibly reveal the need not just for some minor course adjustment in our practical endeavors but a major change of direction or priority.</span><sup class="c1"><a href="#ftnt3" id="ftnt_ref3">[3]</a></sup></p><p class="c0 c12"><span class="c6 c1"></span></p><p class="c0"><span class="c1">This blog post </span><span class="c1">lists</span><span class="c1">&nbsp;</span><span class="c1">possible</span><span class="c1">&nbsp;crucial considerations </span><span class="c1">affecting whether </span><span class="c1">AS advocacy seems likely to be positive on balance, as well as lesser questions affecting how we might prioritize AS relative to other promising cause areas. We include questions that affect broader categories of priorities and intervention types that include at least portions of </span><span class="c1">AS advocacy</span><span class="c6 c1">: longtermism, suffering risks, and moral circle expansion.</span></p><p class="c0 c12"><span class="c6 c1"></span></p><p class="c0"><span class="c1">For simplicity</span><span class="c1">, the </span><span class="c1">questions </span><span class="c1">are phrased in binaries (e.g. Will X happen?, Can we do X?) but are best answered in terms of probabilities (How likely is it that X will happen?) and degrees (</span><span class="c1">To what extent</span><span class="c6 c1">&nbsp;can we do X?).</span></p><p class="c0 c12"><span class="c6 c1"></span></p><p class="c0"><span class="c1">We include references for where certain questions have been explored in more depth. The focus here is not on providing answers, though a key goal of Sentience Institute&rsquo;s </span><span class="c2 c1"><a class="c3" href="https://www.sentienceinstitute.org/research">past</a></span><span class="c1">&nbsp;and </span><span class="c2 c1"><a class="c3" href="https://www.sentienceinstitute.org/research-agenda">ongoing</a></span><span class="c1">&nbsp;research is to shed light on </span><span class="c1">the </span><span class="c6 c1">formulation and likely answers to these questions.</span></p><p class="c0 c12"><span class="c1 c6"></span></p><p class="c0"><span class="c1">Some</span><span class="c1">&nbsp;of these questions were also discussed on our </span><span class="c2 c1"><a class="c3" href="https://www.sentienceinstitute.org/podcast/episode-16.html">podcast episode</a></span><span class="c1">&nbsp;with Tobias Baumann.</span></p><h1 class="c13" id="h.dpmklgui8el"><span class="c11 c1">Should we accept longtermism?</span></h1><p class="c0"><span class="c1">Longtermism has been </span><span class="c1">defined</span><span class="c1">&nbsp;by the </span><span class="c2 c1"><a class="c3" href="https://globalprioritiesinstitute.org/research-agenda-web-version/">Global Priorities Institute (2020)</a></span><span class="c1">&nbsp;as, &ldquo;“the view that the primary determinant of the differences in social value among actions and policies available today is the effect of those actions on the </span><span class="c1">very long-term future.</span><span class="c1">&rdquo; </span><span class="c1">Rejecting this claim could lead to a rejection of AS</span><span class="c1">&nbsp;as a priority for the time being because, if it ever comes into existence, most </span><span class="c1">artificial sentience will presumably exist in the very long-term future</span><span class="c1">.</span><sup class="c1"><a href="#ftnt4" id="ftnt_ref4">[4]</a></sup></p><p class="c0 c12"><span class="c6 c1"></span></p><p class="c0"><span class="c1">Considerations affecting whether we accept or reject longtermism include</span><span class="c6 c1">:</span></p><ul class="c9 lst-kix_ml7jx42wh7m4-0 start"><li class="c0 c4 li-bullet-0"><span class="c1">What obligations do we have to future beings? (</span><span class="c2 c1"><a class="c3" href="https://www.diva-portal.org/smash/get/diva2:170236/FULLTEXT01.pdf">Arrhenius 2000)</a></span></li><li class="c0 c4 li-bullet-0"><span class="c1">When evaluating interventions, should we take into account the numerous (long-term) unintended, indirect effects or only consider the (short-term) intended, direct effects?</span><span class="c1">&nbsp;</span><span class="c1">(</span><span class="c2 c1"><a class="c3" href="https://globalprioritiesinstitute.org/research-agenda-web-version/">GPI 2020</a></span><span class="c1">)</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Should we &ldquo;adopt a zero rate of pure time preference&rdquo; in evaluating interventions? (</span><span class="c2 c1"><a class="c3" href="https://globalprioritiesinstitute.org/research-agenda-web-version/">GPI 2020</a></span><span class="c1">)</span></li></ul><ul class="c9 lst-kix_hzr8alqpso24-0 start"><li class="c0 c4 li-bullet-0"><span class="c1">Should we focus on actions with higher expected value but lower certainty, or lower expected value but higher certainty? (</span><span class="c2 c1"><a class="c3" href="https://globalprioritiesinstitute.org/wp-content/uploads/Hayden-Wilkinson_In-defence-of-fanaticism.pdf">Wilkinson 2020</a></span><span class="c1">&nbsp;and </span><span class="c2 c1"><a class="c3" href="https://reducing-suffering.org/altruists-focus-reducing-short-term-far-future-suffering/#Weak_arguments_against_far-future_dominance">Tomasik 2015</a></span><span class="c6 c1">)</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Can we reliably influence the long-term future? (</span><span class="c2 c1"><a class="c3" href="https://www.sentienceinstitute.org/blog/how-tractable-is-changing-the-course-of-history">Harris and Anthis 2019</a></span><span class="c1">, </span><span class="c2 c1"><a class="c3" href="https://globalprioritiesinstitute.org/wp-content/uploads/Working-paper-10-Christian-Tarsney.pdf">Tarsney 2019</a></span><span class="c1">, and </span><span class="c2 c1"><a class="c3" href="http://everydayutilitarian.com/essays/why-im-skeptical-about-unproven-causes-and-you-should-be-too/">Hurford 2013</a></span><span class="c1">)</span></li></ul><h1 class="c13" id="h.ymidwnrh9meo"><span class="c11 c1">Assuming longtermism, should we focus on reducing suffering risks?</span></h1><p class="c0"><span class="c1">If we accept </span><span class="c1">longtermism</span><span class="c1">, then there are </span><span class="c2 c1"><a class="c3" href="https://80000hours.org/key-ideas/#most-pressing-problems">many cause areas</a></span><span class="c1">&nbsp;we could focus on. One cluster focuses on reducing risks of astronomical suffering in the long-term future (&ldquo;s-risks&rdquo;). </span><span class="c1">AS</span><span class="c1">&nbsp;advocacy seems most promising as a method of reducing s-risks, so questions that affect the promise of this broader category also affect AS.</span><sup class="c1"><a href="#ftnt5" id="ftnt_ref5">[5]</a></sup><span class="c1">&nbsp;</span><span class="c2 c1"><a class="c3" href="https://centerforreducingsuffering.org/arguments-for-and-against-a-focus-on-s-risks/">Baumann (2020)</a></span><span class="c6 c1">&nbsp;summarizes relevant crucial considerations (and provides references for relevant reading). In brief, these are:</span></p><ul class="c9 lst-kix_c8fdfvemucm9-0 start"><li class="c0 c4 li-bullet-0"><span class="c1">&ldquo;How much moral weight [should] we give to reducing (</span><span class="c1">severe</span><span class="c1">, large-scale) suffering or other harms, compared to other moral goals, such as the creation of additional happy lives or the promotion of greater happiness of individuals that are already </span><span class="c1">well-off</span><span class="c6 c1">&rdquo;?</span></li><li class="c0 c4 li-bullet-0"><span class="c1">How much suffering will exist in the future? How much happiness will exist? How easy or difficult will it be to affect these outcomes?</span><sup class="c1"><a href="#ftnt6" id="ftnt_ref6">[6]</a></sup></li><li class="c0 c4 li-bullet-0"><span class="c1">What proportion of expected future suffering lies in &ldquo;</span><span class="c1">worst case</span><span class="c6 c1">&rdquo; scenarios?</span></li></ul><h1 class="c13" id="h.tc1miq47plr"><span class="c1">Assuming longtermism, should we focus on moral circle expansion?</span></h1><p class="c0"><span class="c1">AS</span><span class="c1">&nbsp;advocacy is a form of </span><span class="c2 c1"><a class="c3" href="https://www.sciencedirect.com/science/article/pii/S0016328721000641">moral circle expansion</a></span><span class="c1">&nbsp;(MCE), an increase in the number of beings given moral consideration, such as legal protection.</span><sup class="c1"><a href="#ftnt7" id="ftnt_ref7">[7]</a></sup><span class="c1">&nbsp;Therefore, questions that affect the prioritization of MCE could also affect the prioritization of AS</span><span class="c1">.</span></p><p class="c0 c12"><span class="c6 c1"></span></p><p class="c0"><span class="c2 c1"><a class="c3" href="https://longtermrisk.org/arguments-moral-advocacy/">Baumann (2017)</a></span><span class="c1">&nbsp;has explored arguments for and against &ldquo;moral advocacy&rdquo; or &ldquo;values spreading,&rdquo; which includes but is not limited to MCE.</span><sup class="c1"><a href="#ftnt8" id="ftnt_ref8">[8]</a></sup><span class="c6 c1">&nbsp;Relevant crucial considerations implied by that post include:</span></p><ul class="c9 lst-kix_fn2hg8bsewg7-0 start"><li class="c0 c4 li-bullet-0"><span class="c6 c1">Does advocating for a value system increase the number of people with these values?</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Do persuaded individuals take action in support of their new values, e.g. further advocacy?</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Do the actions of persuaded individuals tend to align with the intentions of the original advocates?</span></li><li class="c0 c4 li-bullet-0"><span class="c6 c1">Will the values that are spread be durable or will they revert to an equilibrium?</span></li><li class="c0 c4 li-bullet-0"><span class="c6 c1">Will the values that are spread be rendered irrelevant, e.g. by human extinction?</span></li><li class="c0 c4 li-bullet-0"><span class="c6 c1">Do value changes influence technological and economic developments?</span></li><li class="c0 c4 li-bullet-0"><span class="c6 c1">Do efforts to spread values encourage equal or greater efforts to spread opposite values?</span></li><li class="c0 c4 li-bullet-0"><span class="c6 c1">Do efforts to spread values encourage moral reflection or competitiveness and partisanship?</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Does values spreading have diminishing returns? I.e. can a small, convinced minority wield outsized influence?</span></li></ul><p class="c0 c12"><span class="c6 c1"></span></p><p class="c0"><span class="c6 c1">Our forthcoming literature review on the causes of public opinion change provides empirical evidence on several of these questions.</span></p><p class="c0 c12"><span class="c6 c1"></span></p><p class="c0"><span class="c2 c1"><a class="c3" href="https://forum.effectivealtruism.org/posts/BY8gXSpGijypbGitT/why-i-prioritize-moral-circle-expansion-over-artificial">Anthis (2018)</a></span><span class="c1">&nbsp;</span><span class="c1">and the commenters on that post</span><span class="c6 c1">&nbsp;raise a number of further crucial considerations relevant to values spreading in general:</span></p><ul class="c9 lst-kix_h84kvyezyn1p-0 start"><li class="c0 c4 li-bullet-0"><span class="c1">Will </span><span class="c1">human descendants &ldquo;find the correct morality (in the sense of moral realism, finding these mind-independent moral facts)&rdquo; and converge towards it, </span><span class="c1">e.g. during a period of </span><span class="c2 c1"><a class="c3" href="https://forum.effectivealtruism.org/tag/long-reflection">long reflection</a></span><span class="c1">?</span></li><li class="c0 c4 li-bullet-0"><span class="c1">How tractable</span><span class="c1">&nbsp;are reflection processes (e.g. </span><span class="c2 c1"><a class="c3" href="https://arbital.com/p/cev/">coherent extrapolated volition</a></span><span class="c1">) to the problem of determining optimal valu</span><span class="c6 c1">es, and will they be affected by current values?</span></li></ul><ul class="c9 lst-kix_wj3518ryvr35-0 start"><li class="c0 c4 li-bullet-0"><span class="c6 c1">Will values be locked-in, e.g. because of developments in AI? If so, when?</span></li><li class="c0 c4 li-bullet-0"><span class="c6 c1">Will the values of some people, such as AI researchers, have a disproportionate influence on the far future? Can they be influenced by targeted interventions?</span></li><li class="c0 c4 li-bullet-0"><span class="c6 c1">Do the values that would improve the quality of the far future converge with the values that would improve the quality of the near future?</span></li></ul><p class="c0 c12"><span class="c6 c1"></span></p><p class="c0"><span class="c2 c1"><a class="c3" href="https://forum.effectivealtruism.org/posts/BY8gXSpGijypbGitT/why-i-prioritize-moral-circle-expansion-over-artificial">Anthis (2018)</a></span><span class="c1">&nbsp;</span><span class="c1">and commenters</span><span class="c1">&nbsp;also raise crucial considerations specific to MCE, some of which have been evaluated in </span><span class="c2 c1"><a class="c3" href="https://www.sentienceinstitute.org/blog/how-tractable-is-changing-the-course-of-history">Harris and Anthis (2019</a></span><span class="c1">):</span></p><ul class="c9 lst-kix_h84kvyezyn1p-0"><li class="c0 c4 li-bullet-0"><span class="c1">Will </span><span class="c1">the moral circle expand to reach all sentient beings?</span></li><li class="c0 c4 li-bullet-0"><span class="c6 c1">Are economic growth and other long-term, indirect factors more important determinants of the size and shape of moral circles than direct MCE efforts?</span></li><li class="c0 c4 li-bullet-0"><span class="c6 c1">Do human biases incline us to work on MCE or on other cause areas?</span></li></ul><p class="c0 c12"><span class="c6 c1"></span></p><p class="c0"><span class="c1">Other crucial considerations, not raised in the above posts, include:</span></p><ul class="c9 lst-kix_dzrkkyna3ewm-0 start"><li class="c0 c4 li-bullet-0"><span class="c1">Will there be competing powerful agents in the far future and what effects will MCE have on the interactions between such agents?</span><sup class="c1"><a href="#ftnt9" id="ftnt_ref9">[9]</a></sup><span class="c1">&nbsp;(</span><span class="c2 c1"><a class="c3" href="https://longtermrisk.org/coordination-challenges-for-preventing-ai-conflict/">Torges 2021</a></span><span class="c6 c1">)</span></li><li class="c0 c4 li-bullet-0"><span class="c1">D</span><span class="c1">o changes in attitudes towards one type of sentient being affect attitudes towards other sentient beings? (</span><span class="c2 c1"><a class="c3" href="https://forum.effectivealtruism.org/posts/bhGuf6uDXd63g6GPx/on-the-longtermist-case-for-working-on-farmed-animals">Aird 2021</a></span><span class="c1">&nbsp;</span><span class="c1">and</span><span class="c1">&nbsp;</span><span class="c2 c1"><a class="c3" href="https://www.sentienceinstitute.org/downloads/Perspective%2520taking%2520and%2520nonhuman%2520groups%2520-%2520preprint.pdf">Ladak et al. 2021</a></span><span class="c6 c1">)</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Does successful advocacy for one type of sentient being build capacity for advocacy for other types of sentient beings or will the movement dissipate once its narrower goals are achieved?</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Will the moral circle expand too far, leading to suboptimal resource allocation? (</span><span class="c2 c1"><a class="c3" href="http://gunkelweb.com/coms647/texts/darling_robot_rights.pdf">Darling 2016</a></span><span class="c1">)</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Is the tractability of MCE decreased if the intended beneficiaries cannot advocate for their own interests? (</span><span class="c2 c1"><a class="c3" href="https://forum.effectivealtruism.org/posts/o4HX48yMGjCrcRqwC/what-helped-the-voiceless-historical-case-studies#Two_Ways_That_Excluded_Groups_Benefit_Luck_and_Power_">Baker 2020</a></span><span class="c1">)</span></li></ul><h1 class="c13" id="h.w7y9f2jg3her"><span class="c1">Assuming</span><span class="c11 c1">&nbsp;longtermism and a focus on moral circle expansion, should we focus on artificial sentience?</span></h1><p class="c0"><span class="c1">The questions listed above all affect whether we should focus on AS,</span><sup class="c1"><a href="#ftnt10" id="ftnt_ref10">[10]</a></sup><span class="c6 c1">&nbsp;though there are many other questions specific to AS.</span></p><p class="c0 c12"><span class="c6 c1"></span></p><p class="c0"><span class="c1">Crucial considerations relating to the scale of the problem addressed by </span><span class="c1">AS</span><span class="c6 c1">&nbsp;advocacy include:</span></p><ul class="c9 lst-kix_ur7ya1g0zgi8-0 start"><li class="c0 c4 li-bullet-0"><span class="c1">Are current artificial entities sentient?</span><span class="c1">&nbsp;(</span><span class="c2 c1"><a class="c3" href="https://arxiv.org/abs/1410.8233">Tomasik 2014a</a></span><span class="c1">, </span><span class="c2 c1"><a class="c3" href="https://www.sentienceinstitute.org/blog/what-is-sentience">Anthis 2018</a></span><span class="c6 c1">)</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Will future artificial entities be sentient? (</span><span class="c2 c1"><a class="c3" href="http://lukemuehlhauser.com/wp-content/uploads/Reggia-The-rise-of-machine-consciousness-Studying-consciousness-with-computational-models.pdf">Reggia 2013</a></span><span class="c1">, </span><span class="c2 c1"><a class="c3" href="https://doi.org/10.31234/osf.io/8mbsk">Francken et al. 2021</a></span><span class="c6 c1">)</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Will artificial sentience suffer in practice? (</span><span class="c2 c1"><a class="c3" href="https://longtermrisk.org/risks-of-astronomical-future-suffering/">Tomasik 2011</a></span><span class="c1">, </span><span class="c2 c1"><a class="c3" href="https://longtermrisk.org/files/Sotala-Gloor-Superintelligent-AI-and-Suffering-Risks.pdf">Sotala and Gloor 2017</a></span><span class="c6 c1">)</span></li><li class="c0 c4 li-bullet-0"><span class="c1">How many sentient artificial beings will exist? What proportion of future sentient lifeforms will be artificial?</span><span class="c1">&nbsp;What proportion of suffering will artificial sentience account for?</span><span class="c1">&nbsp;(</span><span class="c2 c1"><a class="c3" href="https://reducing-suffering.org/how-likely-is-wireheading/">Tomasik 2014b</a></span><span class="c1">, </span><span class="c2 c1"><a class="c3" href="https://forum.effectivealtruism.org/posts/NfkEqssr7qDazTquW/the-expected-value-of-extinction-risk-reduction-is-positive">Brauner and Grosse-Holz 2018</a></span><span class="c1">)</span><span class="c6 c1">, </span></li><li class="c0 c4 li-bullet-0"><span class="c1">How would </span><span class="c1">AS advocacy</span><span class="c1">&nbsp;affect the trajectory of academic work related to artificial sentience? E.g. would it lead to new ideas and foci or just reinforce the </span><span class="c1">current ones</span><span class="c6 c1">?</span></li><li class="c0 c4 li-bullet-0"><span class="c1">What effects would </span><span class="c1">AS advocacy</span><span class="c6 c1">&nbsp;have on AI designers and researchers? E.g. would it polarize these communities? Would it slow down AI safety research?</span></li><li class="c0 c4 li-bullet-0"><span class="c1">What effects would </span><span class="c1">AS advocacy</span><span class="c1">&nbsp;</span><span class="c1">have on the credibility and resources of other movements with which it is associated (e.g. animal advocacy, effective altruism)?</span></li></ul><p class="c0 c12"><span class="c6 c1"></span></p><p class="c0"><span class="c6 c1">Crucial considerations relating to whether the problem is neglected and therefore whether there are likely to be low-hanging fruit for positive impact include:</span></p><ul class="c9 lst-kix_ur7ya1g0zgi8-0"><li class="c0 c4 li-bullet-0"><span class="c6 c1">Will an AS advocacy movement develop anyway?</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Will ongoing discussion of &ldquo;robot rights&rdquo; and related topics (e.g. </span><span class="c2 c1"><a class="c3" href="https://arxiv.org/ftp/arxiv/papers/2102/2102.04215.pdf">in academia</a></span><span class="c1">, in </span><span class="c2 c1"><a class="c3" href="https://www.canberra.edu.au/about-uc/faculties/busgovlaw/about-us/school-of-law/the-canberra-law-review/attachments/Arnold-and-Gough-Turings-People.pdf">sci-fi</a></span><span class="c1">) extend to include other categories of artificial sentience, such as </span><span class="c2 c1"><a class="c3" href="https://reducing-suffering.org/what-are-suffering-subroutines/">suffering subroutines</a></span><span class="c6 c1">?</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Are the plausible &ldquo;asks&rdquo; that advocates could make meaningfully different from adjacent work that is already being done, e.g. animal advocacy, consciousness research? (</span><span class="c2 c1"><a class="c3" href="https://arxiv.org/abs/2008.01339">Lima et al. </a></span><span class="c2 c1"><a class="c3" href="https://arxiv.org/abs/2008.01339">2020</a></span><span class="c1">, </span><span class="c2 c1"><a class="c3" href="https://link.springer.com/article/10.1007%252Fs43681-021-00065-0">Owe and Baum 2021</a></span><span class="c6 c1">)</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Will artificial sentience be autonomous, capable of rational decision-making, or possess other characteristics beyond sentience that might affect (the perception of) moral obligations towards it or its capacity to advocate for its own interests? (</span><span class="c2 c1"><a class="c3" href="https://www.google.co.uk/books/edition/The_Age_of_Em/DMgwDAAAQBAJ?hl%3Den%26gbpv%3D1%26dq%3DAge%2Bof%2BEm%26pg%3DPP1%26printsec%3Dfrontcover">Hanson 2016</a></span><span class="c1">, </span><span class="c2 c1"><a class="c3" href="https://ruj.uj.edu.pl/xmlui/bitstream/handle/item/42187/The%2520Rise%2520of%2520Social%2520Robots.pdf?sequence%3D1%26isAllowed%3Dy">Campa </a></span><span class="c1 c2"><a class="c3" href="https://ruj.uj.edu.pl/xmlui/bitstream/handle/item/42187/The%2520Rise%2520of%2520Social%2520Robots.pdf?sequence%3D1%26isAllowed%3Dy">2016</a></span><span class="c6 c1">)</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Will artificial sentience be created directly by humans, or in some other way that affects (the perception of) moral obligations towards it? (</span><span class="c2 c1"><a class="c3" href="https://books.google.co.uk/books/about/Superintelligence.html?id%3D7_H8AwAAQBAJ">Bostrom 2014b</a></span><span class="c6 c1">)</span></li></ul><p class="c0 c12"><span class="c6 c1"></span></p><p class="c0"><span class="c6 c1">Crucial considerations relating to how solvable the problem is include:</span></p><ul class="c9 lst-kix_ur7ya1g0zgi8-0"><li class="c0 c4 li-bullet-0"><span class="c1">Do common biases and attitudes like speciesism, substratism, </span><span class="c1">anthropomorphism</span><span class="c1">, scope insensitivity, and short-termism make </span><span class="c1">AS advocacy</span><span class="c1">&nbsp;(in)tractable? (</span><span class="c2 c1"><a class="c3" href="https://www.sentienceinstitute.org/blog/the-importance-of-artificial-sentience">Harris and Anthis 2021</a></span><span class="c6 c1">)</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Can the trajectory (e.g. development, spread, and regulation) of new technologies be influenced in its early stages by thoughtful actors? (</span><span class="c2 c1"><a class="c3" href="https://ora.ox.ac.uk/objects/uuid:ea3c7cb8-2464-45f1-a47c-c7b568f27665">Leung 2019</a></span><span class="c1">, </span><span class="c2 c1"><a class="c3" href="https://www.sciencedirect.com/science/article/abs/pii/S0195666319304829#!">Mohor&#269;ich and Reese 2019</a></span><span class="c6 c1">)</span></li><li class="c0 c4 li-bullet-0"><span class="c1">Are there any &ldquo;asks&rdquo; that advocates could make of the institutions that they target that would benefit artificial sentience? (</span><span class="c1">Faville forthcoming</span><span class="c1">, </span><span class="c2 c1"><a class="c3" href="https://www.sentienceinstitute.org/blog/institutional-tactics">Harris 2020</a></span><span class="c6 c1">)</span></li><li class="c0 c4 li-bullet-0"><span class="c1">How much leverage would thoughtful, effectiveness-focused advocates have over a nascent AS advocacy movement? (</span><span class="c2 c1"><a class="c3" href="https://www.sentienceinstitute.org/blog/the-importance-of-artificial-sentience">Harris and Anthis 2021</a></span><span class="c6 c1">)</span></li><li class="c0 c4 li-bullet-0"><span class="c6 c1">Is there sufficient interest in this topic to secure the necessary funding for relevant work?</span></li></ul><hr class="c15"><div><p class="c8"><a href="#ftnt_ref1" id="ftnt1">[1]</a><span class="c5">&nbsp;AS advocacy could involve requests similar to other social movements focused on moral circle expansion, such as demanding legal safeguards to protect against the exploitation of artificial sentience for labor, entertainment, or scientific research. Less ambitious goals could include encouraging attitude change, asking for symbolic commitments, or supporting relevant research.</span></p></div><div><p class="c8"><a href="#ftnt_ref2" id="ftnt2">[2]</a><span class="c7">&nbsp;A more developed movement around AS advocacy might cost similar amounts to other social movements focused on moral circle expansion. For comparison, </span><span class="c2 c7"><a class="c3" href="https://www.sentienceinstitute.org/fair-trade#organizational-resources">Harris (2021)</a></span><span class="c7">&nbsp;notes that, &ldquo;it seems likely that the total resources dedicated to Fair Trade nonprofits each year does not currently substantially exceed $100 million,&rdquo; and </span><span class="c2 c7"><a class="c3" href="https://www.effectivealtruism.org/articles/lewis-bollard-lessons-learned-in-farm-animal-welfare/">Bollard&rsquo;s (2020)</a></span><span class="c5">&nbsp;&ldquo;best estimate&rdquo; of the spending by nonprofits in the farmed animal movement is $165 million per year. The case for AS advocacy potentially being especially cost-effective mostly rests on potential vast positive effects, although unusually low costs also seem plausible, e.g. if the number of potential &ldquo;asks&rdquo; is more limited than in other movements.</span></p></div><div><p class="c8"><a href="#ftnt_ref3" id="ftnt3">[3]</a><span class="c7">&nbsp;</span><span class="c2 c7"><a class="c3" href="http://www.stafforini.com/blog/bostrom/">Bostrom (2014a)</a></span><span class="c5">&nbsp;added that, &ldquo;[w]ithin a utilitarian context, one can perhaps try to explicate it as follows: a crucial consideration is a consideration that radically changes the expected value of pursuing some high-level subgoal. The idea here is that you have some evaluation standard that is fixed, and you form some overall plan to achieve some high-level subgoal. This is your idea of how to maximize this evaluation standard. A crucial consideration, then, would be a consideration that radically changes the expected value of achieving this subgoal.&rdquo;</span></p></div><div><p class="c8"><a href="#ftnt_ref4" id="ftnt4">[4]</a><span class="c7">&nbsp;If you think artificial sentience will be developed in large numbers soon, there might still be a neartermist case for prioritizing AS, similar to the </span><span class="c2 c7"><a class="c3" href="https://www.effectivealtruism.org/articles/cause-profile-animal-welfare/">neartermist case</a></span><span class="c5">&nbsp;for prioritizing animal advocacy.</span></p></div><div><p class="c8"><a href="#ftnt_ref5" id="ftnt5">[5]</a><span class="c7">&nbsp;Generalized </span><span class="c2 c7"><a class="c3" href="https://www.sciencedirect.com/science/article/pii/S0016328721000641">moral circle expansion</a></span><span class="c7">&nbsp;(MCE) may have value beyond reducing s-risks since an insufficiently broad moral circle might lead to a suboptimal allocation of resources even if </span><span class="c14 c7">all </span><span class="c5">sentient beings experience net positive lives (or suffering is only mild/rare). However, MCE might only be comparably cost-effective to other longtermist cause areas and interventions if the arguments underlying a focus on suffering risks also hold.</span></p></div><div><p class="c8"><a href="#ftnt_ref6" id="ftnt6">[6]</a><span class="c7">&nbsp;Of course, these questions could be broken down into many smaller sub-questions. For example, </span><span class="c2 c7"><a class="c3" href="https://forum.effectivealtruism.org/posts/BY8gXSpGijypbGitT/why-i-prioritize-moral-circle-expansion-over-artificial">Anthis (2018)</a></span><span class="c5">&nbsp;lists the following questions:</span></p><ul class="c9 lst-kix_h84kvyezyn1p-0"><li class="c0 c4 li-bullet-0"><span class="c7">How</span><span class="c7">&nbsp;</span><span class="c5">likely is it that powerful beings in the far future &ldquo;will use large numbers of less powerful sentient beings, such as for recreation (e.g. safaris, war games), a labor force (e.g. colonists to distant parts of the galaxy, construction workers), scientific experiments, threats, (e.g. threatening to create and torture beings that a rival cares about), revenge, justice, religion, or even pure sadism?&rdquo;</span></li><li class="c0 c4 li-bullet-0"><span class="c7">How likely is it that, &ldquo;</span><span class="c7">technology and efficiency</span><span class="c5">&nbsp;will remove the need for powerless, high-suffering, instrumental moral patients?&rdquo;</span></li><li class="c0 c4 li-bullet-0"><span class="c7">How </span><span class="c7">likely is it that human descendents &ldquo;will optimize their resources for happiness (i.e. create hedonium) relative to optimizing for suffering (i.e. create dolorium)?&rdquo;</span></li><li class="c0 c4 li-bullet-0"><span class="c5">Will evolutionary forces continue to shape the capacities and experiences of sentient beings?</span></li></ul><p class="c0 c12"><span class="c5"></span></p><p class="c0"><span class="c2 c7"><a class="c3" href="https://forum.effectivealtruism.org/posts/wicAtfihz2JmPRgez/crucial-questions-for-longtermists#A_high_level_overview_of_the_crucial_questions_for_longtermists">Aird (2020)</a></span><span class="c5">&nbsp;lists a number of other sub-questions.</span></p></div><div><p class="c8"><a href="#ftnt_ref7" id="ftnt7">[7]</a><span class="c7">&nbsp;Or to increase the </span><span class="c7 c14">extent </span><span class="c5">to which those beings are given moral consideration, without necessarily affecting total numbers.</span></p></div><div><p class="c8"><a href="#ftnt_ref8" id="ftnt8">[8]</a><span class="c5">&nbsp;The answers to these questions may depend on the specific values being encouraged (e.g. MCE vs. suffering-focused ethics, concern for farmed animals vs. artificial sentience) and the specific manner in which they are encouraged (e.g. technical academic papers vs. confrontational protests).</span></p></div><div><p class="c8"><a href="#ftnt_ref9" id="ftnt9">[9]</a><span class="c7">&nbsp;</span><span class="c7">For example, if MCE successfully influences all powerful future agents, then this may reduce the risk of large-scale suffering through blackmail and threats, since all the agents will be more averse to such outcomes. However, it could also incentivize the use of blackmail by making it a more potent weapon. If it influences some powerful agents but not others, this could increase imbalances in values, incentivizing some agents to use blackmail (and disincentivizing others). However, MCE might also decrease imbalances between powerful agents.</span></p></div><div><p class="c8"><a href="#ftnt_ref10" id="ftnt10">[10]</a><span class="c7">&nbsp;Many of the questions that apply to values spreading or MCE might apply to</span><span class="c1 c7">&nbsp;AS but ha</span><span class="c5">ve answers that differ from the norm for those broader categories. For example, we might find that attitude changes relating to artificial sentience are more likely to last into the long term because persuaded individuals are less likely to hear opposing arguments on this topic than on topics like animal rights.</span></p></div></body></html>
</div>




    <hr>
    <div class="container newsletter-container ">
      <p>Subscribe to our newsletter to receive updates on our research and activities. We average one to two emails per year.</p>
      <div id="mc_embed_signup">
        <form action="//sentienceinstitute.us15.list-manage.com/subscribe/post?u=d898f823d035e0601866e68d6&amp;id=cbf2d915a6" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
          <div id="mc_embed_signup_scroll">
            <input type="email" value="" name="EMAIL" class="email form-input" id="mce-EMAIL" placeholder="Email address" required>
            <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
            <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_d898f823d035e0601866e68d6_cbf2d915a6" tabindex="-1" value=""></div>
            <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
          </div>
        </form>
      </div>
    </div>
    
    <footer class="footer">
      <div class="container">
        <div class="row">
          <div class="col-md-2">
            <div><span class="bold">Contact us: </span><a href="mailto:info@sentienceinstitute.org">info@sentienceinstitute.org</a></div>
            <div class="icons">
              <!-- <a href="/rss.xml"><i class="material-icons">rss_feed</i></a> -->
              <a href="https://www.facebook.com/sentienceinstitute"><img class="icon" src="../img/icons/icon_facebook_white.png"/></a>
              <a href="https://www.twitter.com/sentienceinst"><img class="icon" src="../img/icons/icon_twitter_white.png"/></a>
            </div>
          </div>
          <div class="col-md-10 last-column">
            <div>
              © 2018 Sentience Institute
            </div>
            <div>
              <a href="/terms">Terms and Conditions &amp; Privacy Policy</a>
            </div>
            <div>
              Thank you, <a href="https://weanimals.org/">Jo-Anne McArthur</a>, for granting us the use of so many photos.
            </div>
          </div>
        </div>
      </div>
    </footer>
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/TweenMax.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js" integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn" crossorigin="anonymous"></script>
    <script src="/js/ready.js?v=@version@"></script>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-100318911-1', 'auto');
      ga('send', 'pageview');

    </script>
    
  </body>
</html>
