<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

    <meta name="author" content="Sentience Institute" />

    <meta property="og:site_name" content="Sentience Institute" />
    <meta property="fb:app_id" content="302735083502826" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:site" content="@sentienceinst" />

    
    

    
    <meta property="description" content="At Sentience Institute, we operate under the principle that moral circle expansion is a key strategy for reducing s-risks, particularly those related to artificial sentience....." />
    <meta property="og:description" content="At Sentience Institute, we operate under the principle that moral circle expansion is a key strategy for reducing s-risks, particularly those related to artificial sentience....." />
    
    
    <title>Sentience Institute | Psychological Perspectives Relevant to Artificial Sentience</title>
    <meta property="title" content="Psychological Perspectives Relevant to Artificial Sentience" />
    <meta property="og:title" content="Psychological Perspectives Relevant to Artificial Sentience" />
    
    
    
    
    <meta property="og:url" content="http://www.sentienceinstitute.org/blog/psychology-and-artificial-sentience" />
    <meta property="og:image" content="http://www.sentienceinstitute.org/img/blog/20210806.png" />
    


    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico?v=1">
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,600" rel="stylesheet">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="../css/sentienceinstitute.css?v=2.0.1" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <link href="../css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <nav class="navbar navbar-inverse navbar-toggleable-sm fixed-top">
      <div class="container">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarText" aria-controls="navbarText" aria-expanded="false">
          <span class="navbar-toggler-icon"></span>
        </button>
        <a class="navbar-brand" href="/">
          <!-- <img class="nav-logo" src="../img/logo/SI_logo_white_200px.png"/> -->
          <img class="nav-logo-brandmark" src="../img/logo/SI_brandmark_white_heavier_web.png"/>
          <div class="nav-logo-text">
            <span>Sentience</span>
            <span class="nav-logo-text-institute">Institute</span>
          </div>
        </a>
        <div id="navbarText" class="collapse navbar-collapse">
          <ul class="navbar-nav">
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
                Research<span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
                <li><a href="/foundational-questions-summaries">Foundational Questions Summaries</a></li>
                <li><a href="/research">Reports</a></li>
                <li><a href="/research-agenda">Agenda</a></li>
                <!-- <li><a href="/press">Press Releases</a></li> -->
              </ul>
            </li>
            <li class="nav-item"><a class="nav-link" destination="/media">Media</a></li>
            <li class="nav-item"><a class="nav-link" destination="/podcast">Podcast</a></li>
            <li class="nav-item"><a class="nav-link" destination="/blog">Blog</a></li>
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
                About Us<span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
                <li><a href="/mission">Our Mission</a></li>
                <li><a href="/perspective">Our Perspective</a></li>
                <li><a href="/team">Our Team</a></li>
                <li class="nav-item"><a class="nav-link" href="/get-involved">Get Involved</a></li>
                <li><a href="/transparency">Transparency</a></li>
                <li><a href="/faq">FAQ</a></li>
              </ul>
            </li>
            <li class="nav-item nav-donate"><a class="nav-link" destination="/donate">Donate</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>
    




<div class="container image-container" img-id="20210806" style="background-image: url(/img/blog/20210806.png);">
  
</div>

<div class="container first-container gdoc-html-container blog-container psychology-and-artificial-sentience-container">
  <div class="title">
    Psychological Perspectives Relevant to Artificial Sentience
  </div>
  <div class="author-info">
    
    <div class="author">
      <div class="author-img"><img src="../img/team/janet.png"/></div>
      <div class="author-name-and-role">
      <div class="author-name">Janet Pauketat</div>
      <div class="author-role">Research Fellow</div>
    </div>
  </div>
  
  </div>
  <div class="date">
    August 08, 2021
  </div>
  <html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"></head><body class="c41"><p class="c17"><span class="c23">Edited by Ali Ladak</span><span class="c23">&nbsp;and Jamie Harris. Many thanks to Jacy Reese Anthis and Silvio Curtis for reviewing and providing feedback.</span></p><h1 class="c15" id="h.jtw78eae74sq"><span class="c3 c27">Abstract</span></h1><p class="c10"><span>At</span><span>&nbsp;Sentience Institute, we operate under the principle that moral circle expansion is a key strategy for reducing </span><span class="c4"><a class="c9" href="https://forum.effectivealtruism.org/posts/MCfa6PaGoe6AaLPHR/s-risk-faq">s-risks</a></span><span>, particularly those related to </span><span class="c4"><a class="c9" href="https://www.sentienceinstitute.org/blog/the-importance-of-artificial-sentience">artificial sentience</a></span><span>.</span><span>&nbsp;Like SI, psychologists have been studying moral circle expansion and the m</span><span>oral inclusio</span><span class="c3 c13">n of humans and nonhumans alike. In this post, we provide an overview of the psychological science of moral inclusion. Then we review psychological research on some traditional correlates of the moral consideration of artificial entities, on social robot and human relations, and on the connections between psychology and artificial intelligence (AI). We then provide an overview of the interdisciplinary literature on interpersonal interactions with artificial entities. Finally, we point to research that could aid our nascent understanding of artificial sentience and consider how knowledge about moral inclusion could be applied to improve the future. We hope that you will gain a sense of where psychological science has been building knowledge about moral inclusion and artificial entities, the fundamental connections between psychology and AI, and what areas of research seem promising to advance our moral consideration of sentient artificial entities.</span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span class="c45 c23 c13">*Please note that this post focuses on some of the psychological perspectives on artificial entities that have had more traction and are relevant to the moral consideration of sentient artificial entities. This review is by no means exhaustive of the work on human-robot interaction (HRI), human-computer interaction (HCI), or the psychological study of robots and AIs. </span></p><h1 class="c44 c19" id="h.ymnwatferaae"><span>Table of Contents</span></h1><p class="c19 c42"><span class="c4 c24 c13"><a class="c9" href="#h.k8gi5970ef3q">Introduction</a></span></p><p class="c35 c19"><span class="c4 c24 c13"><a class="c9" href="#h.x61v7wtygxt8">How have psychological scientists conceived of moral inclusion?</a></span></p><p class="c19 c35"><span class="c4 c24 c13"><a class="c9" href="#h.6xfdzv88uh0u">How are artificial entities studied in psychological science?</a></span></p><p class="c2"><span class="c4 c24 c13"><a class="c9" href="#h.r2qpolk04q8">Psychological correlates related to the moral consideration of artificial entities</a></span></p><p class="c2"><span class="c4 c24 c13"><a class="c9" href="#h.a15qcdqgmc68">Social robots and humans</a></span></p><p class="c2"><span class="c4 c24 c13"><a class="c9" href="#h.x2brpfwc6xqn">AIs and humans</a></span></p><p class="c2"><span class="c4 c24 c13"><a class="c9" href="#h.ktdqz6qq35fb">Psychology, neuroscience, and AI</a></span></p><p class="c2"><span class="c4 c24 c13"><a class="c9" href="#h.cd7cszqe7jhm">Interpersonal interactions with artificial entities</a></span></p><p class="c35 c19"><span class="c4 c24 c13"><a class="c9" href="#h.koo5wb5t6x1k">What psychological science research would help better inform our understanding of artificial sentience?</a></span></p><p class="c35 c19"><span class="c4 c24 c13"><a class="c9" href="#h.n1o62923fhnt">How could we apply knowledge about the moral inclusion of artificial entities to improving the future?</a></span></p><p class="c19 c43"><span class="c4 c24 c13"><a class="c9" href="#h.ubazmtyen5v5">Further Reading</a></span></p><h1 class="c44 c19" id="h.k8gi5970ef3q"><span>Introduction</span></h1><p class="c10"><span>When you think about artificial entities, many possible representations might come to mind, from robot vacuums to advanced language generators such as </span><span class="c4"><a class="c9" href="https://www.forbes.com/sites/bernardmarr/2020/10/05/what-is-gpt-3-and-why-is-it-revolutionizing-artificial-intelligence/?sh%3D6db1b8c4481a">GPT-3</a></span><span>&nbsp;to </span><span>future </span><span class="c4"><a class="c9" href="https://www.fhi.ox.ac.uk/brain-emulation-roadmap-report.pdf">whole brain emulations</a></span><span>. In the future, the numbers of </span><span>such artificial entities</span><span>&nbsp;with some degree of </span><span class="c4"><a class="c9" href="https://www.sentienceinstitute.org/blog/what-is-sentience">sentience</a></span><span>, that is, the capacity to have positive and negative experiences, could be vast. The large number of entities combined with the possibility that they will not be granted sufficient moral consideration poses a </span><span class="c4"><a class="c9" href="https://longtermrisk.org/risks-of-astronomical-future-suffering/">risk of astronomical suffering</a></span><span>. </span><span>In this post we review the psychological science of moral inclusion and psychological perspectives on artificial entities, focusing on research relevant to the </span><span class="c4"><a class="c9" href="https://arxiv.org/abs/2102.04215">moral consideration</a></span><span class="c3 c13">&nbsp;of future sentient artificial entities. </span></p><h1 class="c15" id="h.x61v7wtygxt8"><span>How have psychological scientists conceived of moral inclusion?</span></h1><p class="c10"><span>Moral exclusion has been a hallmark of human history, leading to and justifying atrocities against human and nonhuman beings alike.</span><sup><a href="#ftnt1" id="ftnt_ref1">[1]</a></sup><span>&nbsp;Psychologists have thought of the moral circle as a boundary separating entities worthy of moral consideration (i.e., those who are included) from entities unworthy of moral consideration (i.e., those who are excluded).</span><sup><a href="#ftnt2" id="ftnt_ref2">[2]</a></sup><span>&nbsp;Psychological science research supports the idea that humans have a moral circle in which a variety of other beings are either included to some degree or excluded entirely.</span><sup><a href="#ftnt3" id="ftnt_ref3">[3]</a></sup><span class="c3 c13">&nbsp;The table below details some common measurements of moral inclusion used in psychological science.</span></p><p class="c12"><span class="c3 c13"></span></p><p class="c17"><span class="c23">Table 1:</span><span>&nbsp;</span><span>Measures of moral inclusion</span></p><p class="c12"><span class="c3 c13"></span></p><a id="t.3345def0ce0c2ca053cd9ae881f76f7ebc33ec37"></a><a id="t.0"></a><table class="c29"><tbody><tr class="c25"><td class="c18" colspan="1" rowspan="1"><p class="c6"><span class="c16 c13">Measure</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c13 c16">Original citation</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c6"><span class="c16 c13">Example instructions/item</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c6"><span class="c16 c13">Example entities studied</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c6"><span class="c38">Example studies using the measure</span></p></td></tr><tr class="c25"><td class="c18" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Moral Concern</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://www.sciencedirect.com/science/article/pii/S0022103108001613?casa_token%3Dw72Wy5T-o2wAAAAA:XI8eJpWARbYK18mdzvoUri3P-XLuUDIYpk-IBadm_4m6QyJYw5H0cqQ_USkqTuXa5DsJ_05Y-Q">Laham, 2009</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Below is a list of entities. Please select those that you feel morally obligated to show concern for.</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Companion animals, wild animals, food/meat animals, whole brain emulation, robot, young girl, baby, brain-dead person</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://repositorio.iscte-iul.pt/handle/10071/19494">Camacho, 2019</a></span><span class="c1">; </span><span class="c0"><a class="c9" href="https://www.sentienceinstitute.org/downloads/Perspective%20taking%20and%20nonhuman%20groups%20-%20preprint.pdf">Ladak et al., 2021</a></span><span>; </span><span class="c0"><a class="c9" href="https://onlinelibrary.wiley.com/doi/full/10.1002/ejsp.2497">Leite et al., 2019</a></span><span class="c1">; </span><span class="c0"><a class="c9" href="https://www.sciencedirect.com/science/article/abs/pii/S0195666310003648">Loughnan et al., 2010</a></span></p></td></tr><tr class="c25"><td class="c18" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Moral Expansiveness Scale</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://pubmed.ncbi.nlm.nih.gov/26751743/">Crimston et al., 2016</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">In which circle of moral concern would you put the following entities?</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Family member, co-worker, chicken, chimpanzee, redwood tree, coral reef </span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://www.sciencedirect.com/science/article/abs/pii/S0272494418305073">Bastian et al., 2019</a></span><span class="c1">; </span><span class="c0"><a class="c9" href="https://journals.plos.org/plosone/article?id%3D10.1371/journal.pone.0197819">Neldner et al., 2018</a></span><span>; </span><span class="c0"><a class="c9" href="https://link.springer.com/article/10.1007/s12144-020-00615-5">Takamatsu, 2020</a></span><span class="c3 c1">&nbsp;</span></p></td></tr><tr class="c25"><td class="c18" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Moral Inclusion/Exclusion of Other Groups Scale</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://link.springer.com/article/10.1007%252Fs11205-016-1458-3">Passini &amp; Morselli, 2017</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">(values held by this group represent a threat to our well-being) &lt;---&gt; &nbsp;(values held by this group represent an opportunity for our well-being)</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Ethnic or cultural groups different from your own</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7110174/">Passini &amp; Villano, 2018</a></span></p></td></tr><tr class="c25"><td class="c18" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Moral Regard for Outgroups</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://psycnet.apa.org/record/2003-00779-013">Reed &amp; Aquino, 2003</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">To what extent do you believe you have a moral or ethical obligation to show concern for the welfare and interests of [people from another country]?</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">People from another country, strangers, people who practice a different religion than you, people of different ethnicities than you, refugees, the environment</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/ejsp.1871">Bratanova et al., 2012</a></span><span class="c1">; </span><span class="c0"><a class="c9" href="https://journals.aom.org/doi/abs/10.5465/amj.2010.1023">Leavitt et al., 2012</a></span><span class="c1">; </span><span class="c0"><a class="c9" href="https://link.springer.com/article/10.1007/s12144-020-00615-5">Takamatsu, 2020</a></span></p></td></tr><tr class="c25"><td class="c18" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Mutualism</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://conbio.onlinelibrary.wiley.com/doi/full/10.1111/j.1523-1739.2009.01374.x?casa_token%3D6Vg5Rygq29QAAAAA%253AbBcQRyPs7E8L7928hI3-IacJwqqCSh_ZLzuXTDpTZB7gE1RZ_rlRcI3ovEmr32WzXzkNAZv-dFT3JJE">Teel &amp; Manfredo, 2009</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">I view all living things as part of one big family.</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Wildlife (e.g., wolves, polar bears, lynx)</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://www.sciencedirect.com/science/article/abs/pii/S0006320719311929?via%253Dihub">Manfredo et al., 2020</a></span><span class="c1">; </span><span class="c0"><a class="c9" href="https://link.springer.com/article/10.1007/s10344-011-0531-0">Vaske et al., 2011</a></span></p></td></tr><tr class="c25"><td class="c18" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Scope of Justice/Moral Exclusion Scale</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://spssi.onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-4560.1993.tb00909.x?casa_token%3DKg1_1E97MBIAAAAA:377l1xC5NnfLQVgEHd0ewU8gDVZOH7qhc3QaZktthRFbegpkmOKYsf7kVFHcj1YXzGxg-cVHfAHWs18">Opotow, 1993</a></span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">I believe that considerations of fairness apply to [Muslims] too.</span></p></td><td class="c34" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Muslim people, Jewish people, Roma people, insects</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://www.tandfonline.com/doi/full/10.1080/00224545.2018.1456396">Hadarics &amp; Kende; 2019</a></span><span class="c1">; </span><span class="c0"><a class="c9" href="https://www.sciencedirect.com/science/article/pii/S0147176717303218">Hadarics &amp; Kende, 2018</a></span></p></td></tr></tbody></table><p class="c12"><span class="c3 c13"></span></p><p class="c10"><span class="c3 c13">Psychologists have also studied how various values, personality orientations, perceptions, attitudes, and emotions are related to moral inclusion. Below we summarize some of these relationships. </span></p><p class="c12"><span class="c3 c13"></span></p><p class="c17"><span class="c23">Table 2:</span><span>&nbsp;Psychological correlates of</span><span>&nbsp;moral inclusion</span></p><p class="c12"><span class="c3 c13"></span></p><a id="t.6a4659804b7e0d5ce7e70d08374f1e9fcbe17134"></a><a id="t.1"></a><table class="c29"><tbody><tr class="c47"><td class="c8" colspan="1" rowspan="1"><p class="c6"><span class="c16 c13">Construct</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c6"><span class="c16 c13">Definition</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c38">Relationship to moral inclusion</span></p></td><td class="c30" colspan="1" rowspan="1"><p class="c6"><span class="c16 c13">Relevant citation(s)</span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Anthropomorphism</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">The attribution of human-like physical features and mental capacities to nonhuman entities</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">A stronger tendency to anthropomorphize predicts greater moral consideration of nonhuman agents.</span></p></td><td class="c30" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://journals.sagepub.com/doi/10.1177/1745691610369336">Waytz et al., 2010</a></span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Compassion</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">A moral emotion felt in response to others&rsquo; suffering coupled with a motivation to help</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Compassion motivates moral judgments and actions that serve to reduce suffering, especially suffering as a result of unjustified harms.</span></p></td><td class="c30" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://pubmed.ncbi.nlm.nih.gov/20438142/">Goetz et al., 2010</a></span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Empathy</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c6"><span class="c1">&ldquo;Empathy is a stimulated emotional state that relies on the ability to perceive, understand and care about the experiences or perspectives of another&rdquo; and incorporates cognitive, affective, and motivational components (</span><span class="c0"><a class="c9" href="https://onlinelibrary.wiley.com/doi/pdf/10.1111/cura.12257?casa_token%3DOdCW3dbFO3cAAAAA:1CTLWWItIFCfBdBOlzGgFdYfmFffU-prxWQvpleNHwmwQgV6U8B21EUdmwJDP4kOJyGRjqdeqgMV7Q">Young et al., 2018</a></span><span class="c3 c1">).</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Empathy typically predicts moral care and helping behavior. However, as in the &ldquo;meat paradox&rdquo; empathy may be undermined by moral disengagement.</span></p></td><td class="c30" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://www.sciencedirect.com/science/article/pii/S0191886920302920?casa_token%3DnmXPwCZDo6kAAAAA:Y1zszn2IGCY17kjVR3_UeQV-2UOa30vcWorHgQQBElH2VFTabix5UO_UQq8JfI3vpU8fWURjrQ">Camilleri et al., 2020</a></span><span class="c1">; </span><span class="c0"><a class="c9" href="https://journals.sagepub.com/doi/full/10.1177/0190272510361435?casa_token%3DOp32YYmWozsAAAAA%253A6euTDdDculWaPAP-RAMefNVOjg3w8TZnKaoXPd8uw-o31GZC6oU7XDNGhFnTRh0-BUOja3IEuaz7">Wilhelm &amp; Bekkers, 2010</a></span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Global Citizenship</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c6"><span class="c1">&ldquo;awareness, caring, and embracing cultural diversity while promoting social justice and sustainability, coupled with a sense of responsibility to act&rdquo; (</span><span class="c0"><a class="c9" href="https://onlinelibrary.wiley.com/doi/abs/10.1080/00207594.2012.701749">Reysen &amp; Katzarska-Miller, 2013</a></span><span class="c1">, p. 858</span><span class="c3 c1">)</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Stronger global citizenship predicts morally expansive attitudes and behaviors such as pro-environmentalism, support for peace, and human rights activism.</span></p></td><td class="c30" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://onlinelibrary.wiley.com/doi/abs/10.1111/pops.12572">McFarland et al., 2019</a></span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Mind Perception</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">The attribution of beliefs, intentions, and mental states such as thoughts and emotions to others</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">More mind perception is linked with greater moral consideration.</span></p></td><td class="c30" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://www.frontiersin.org/articles/10.3389/fpsyg.2018.01230/full">Wang &amp; Krumhuber, 2018</a></span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Moral Identity</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c6"><span class="c1">&ldquo;the degree to which being a moral person is important to an individual&rsquo;s identity&rdquo; (</span><span class="c0"><a class="c9" href="https://psycnet.apa.org/record/2011-17902-014">Hardy &amp; Carlo, 2011</a></span><span class="c3 c1">, p. 212)</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Moral identity is weakly associated with moral behaviors including avoiding antisocial actions like aggression, behaving ethically, and prosocial actions like volunteering.</span></p></td><td class="c30" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://journals.sagepub.com/doi/10.1037/gpr0000062">Hertz &amp; Krettenauer, 2016</a></span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Moral Foundations </span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">A model of moral judgment suggesting that moral behavior is based on variation in the strength of care/harm, fairness/cheating, loyalty/betrayal, authority/subversion, and sanctity/degradation values</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Holding stronger care/harm and fairness/cheating values is linked with a more expansive moral circle (i.e., showing concern for friends in addition to family, for the world in addition to the nation, and for nonhuman animals in addition to humans).</span></p></td><td class="c30" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://www.nature.com/articles/s41467-019-12227-0">Waytz et al., 2019</a></span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Moral Motives </span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">A model of moral judgment suggesting that moral behavior comes from the intersection of approach-avoidance motives and focus of moral concern </span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Approach motives combined with a focus on others underpins the desire to help others and treat them fairly.</span></p></td><td class="c30" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://journals.sagepub.com/doi/10.1177/1088868313480274">Janoff-Bulman &amp; Carnes, 2013</a></span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Unconditional Respect</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">A moral orientation towards the recognition of another&rsquo;s fundamental integrity and autonomy as a rational being</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Unconditional respect predicts empathy and positive intentions towards human outgroups.</span></p></td><td class="c30" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/ejsp.564">Lalljee et al., 2009</a></span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Social Dominance Orientation</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c6"><span class="c1">&ldquo;</span><span class="c1">the degree to which individuals desire and support a group-based hierarchy and the domination of &lsquo;inferior&rsquo; groups by &lsquo;superior&rsquo; groups&rdquo; (</span><span class="c0"><a class="c9" href="https://psycnet.apa.org/record/1999-02958-000">Sidanius &amp; Pratto, 1999</a></span><span class="c1">, p. 48</span><span class="c3 c1">)</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">A stronger social dominance orientation predicts less moral consideration.</span></p></td><td class="c30" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://www.sciencedirect.com/science/article/pii/S019188691500656X?casa_token%3DI-Ju_onXlAUAAAAA:njXmLbCBc-d7x38wdef4dnGEB3iyB2aBzkQRdCauv3f3VEwUYDW8rMvmvTZwM5JnavBLlg9ESw">Passini &amp; Morselli, 2016</a></span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Speciesism</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c6"><span class="c1">&ldquo;the assignment of different moral worth based on species membership&rdquo; (</span><span class="c0"><a class="c9" href="https://pubmed.ncbi.nlm.nih.gov/29517258/">Caviola et al., 2019</a></span><span class="c3 c1">, p. 1011)</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Higher speciesism is associated with a variety of prejudices (e.g., racism, sexism), a stronger preference for meat snacks, and donating to and investing time in human causes rather than nonhuman causes.</span></p></td><td class="c30" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://pubmed.ncbi.nlm.nih.gov/29517258/">Caviola et al., 2019</a></span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Universalism</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c6"><span class="c1">&ldquo;defining goal: understanding, appreciation, tolerance, and protection for the welfare of </span><span class="c23 c1">all</span><span class="c1">&nbsp;people and for nature&rdquo; (</span><span class="c0"><a class="c9" href="https://scholarworks.gvsu.edu/orpc/vol2/iss1/11/">Schwartz, 2012</a></span><span class="c3 c1">, p. 7)</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Moral consideration is linked with societally- and individually-held universal values.</span></p></td><td class="c30" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://journals.sagepub.com/doi/abs/10.1177/0022022107308992?casa_token%3DN1swdfbD5uAAAAAA:iPG8jgL3s3LpuHog5mHnF05aJHOKRa-xmtiTIsN5CD2pvVU0l1IvZFtu1SPajNZxKOTOeO_dfP75">Schwartz, 2007</a></span></p></td></tr></tbody></table><h1 class="c15" id="h.6xfdzv88uh0u"><span class="c3 c27">How are artificial entities studied in psychological science?</span></h1><p class="c10"><span>Interest is increasing in the psychological antecedents and outcomes of human-robot interaction (HRI) and human-computer interaction (HCI). </span><span>Some of this psychological research may be particularly important to consider in preparation for interacting with sentient artificial entities.</span><span class="c3 c13">&nbsp;We first review research on three consequential psychological correlates studied in relation to the moral consideration of artificial entities. Then, we present some of the psychological science on human-social robot interactions. Next, we examine some of the psychological science informing our understanding of the relationship between humans and AIs. We conclude this section by summarizing foundational interdisciplinary HRI research on interpersonal interactions with artificial entities.</span></p><h2 class="c40 c19" id="h.r2qpolk04q8"><span class="c3 c32">Psychological correlates related to the moral consideration of artificial entities</span></h2><p class="c10"><span class="c3 c13">Two constructs have been particularly important in the psychological study of the moral consideration of artificial entities: anthropomorphism and mind perception. A third construct, substratism, is emerging as important to moral consideration.</span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span>Anthropomorphism involves granting human-like qualities to nonhuman beings, ranging from designing physical qualities like bipedalism and having two forward-facing eyes to attributing mental capacities like having intentions and the capacity to feel complex emotions. </span><span>Anthropomorphism</span><span>&nbsp;can be thought of as the opposite of </span><span>dehumanization, in which human-like qualities are denied to other humans</span><span>,</span><sup><a href="#ftnt4" id="ftnt_ref4">[4]</a></sup><span>&nbsp;leading to moral exclusion. Humanization of robots entails making robots more human-like in terms of their physical, behavioral, and mental attributes and its effects are intertwined with psychological anthropomorphism.</span><sup><a href="#ftnt5" id="ftnt_ref5">[5]</a></sup><span>&nbsp;</span><span class="c4"><a class="c9" href="https://psycnet.apa.org/record/2019-08739-003">Psychological research</a></span><span>&nbsp;has shown that humans are less willing to sacrifice a humanized robot than a machine-like robot during a moral dilemma and that they are less likely to sacrifice any robot </span><span>attributed emotional capacity</span><span>. Similarly, </span><span class="c4"><a class="c9" href="https://www.sciencedirect.com/science/article/abs/pii/S0022103114000067?via%253Dihub">psychological research</a></span><span>&nbsp;has shown that anthropomorphized self-driving cars are </span><span>trusted </span><span>more by humans than non-anthropomorphized self-driving cars or non-autonomous cars.</span><span class="c46">&nbsp;</span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span>Mind perception involves perceiving that another entity has cognitive and experiential capacities. For instance, humans recognize that other humans think and feel. Humans also recognize that many nonhuman animals, like elephants and dolphins, think and feel. </span><span>Studies </span><span>on perceiving the minds of artificial entities have shown that humans tend to attribute cognitive capacities to them, like problem-solving and memory, but not experiential capacities like having emotions.</span><sup><a href="#ftnt6" id="ftnt_ref6">[6]</a></sup><span class="c3 c13">&nbsp;</span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span>An important comment on psychological terminology needs to be made here before continuing. &ldquo;Affect&rdquo; refers to a broad category of emotions, feelings, sentiments, and moods. Psychologists typically consider affect to vary along valence (positive, negative) and arousal/activation (high, low) dimensions. &ldquo;Emotions&rdquo; are brief, intense states arising from and directed toward a stimulus, like anger in response to being insulted. &ldquo;Feeling&rdquo; is a somewhat muddier term but tends to refer to a state that is longer-lasting than an emotion, requires subjective awareness, and can serve as a </span><span class="c4"><a class="c9" href="https://www.researchgate.net/publication/266330418_Feelings-as-Information_Theory">source of information</a></span><span>&nbsp;about the self and the world. &ldquo;Sentiments&rdquo; are enduring, organized systems of emotions about a given stimulus such as long-standing hatred of another social group. &ldquo;Mood&rdquo; refers to a longer-lasting, diffuse state that may not have a specific cause, like being in a happy mood.</span><sup><a href="#ftnt7" id="ftnt_ref7">[7]</a></sup></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span>In psychological science, &ldquo;suffering&rdquo; is not necessarily thought of as analogous to &ldquo;pain&rdquo; nor is it typically conceptualized as an emotion like &ldquo;distress&rdquo;. Instead, the American Psychological Association&rsquo;s (APA) </span><span class="c4"><a class="c9" href="https://dictionary.apa.org/suffering">definition</a></span><span>&nbsp;emphasizes that &ldquo;suffering&rdquo; is the &ldquo;experience&rdquo; of pain or distress. We can consider &ldquo;pain&rdquo;, &ldquo;distress&rdquo;, and &ldquo;suffering&rdquo; in terms of traditional psychological theories of emotion. There is a clear biological basis for pain, distress, and suffering consistent with </span><span class="c4"><a class="c9" href="https://academic.oup.com/scan/article/12/1/1/2823712">Barrett&rsquo;s theory of constructed emotion</a></span><span>&nbsp;and </span><span class="c4"><a class="c9" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3044650/">research</a></span><span>&nbsp;showing the integration of negative affect and pain in the brain.</span><sup><a href="#ftnt8" id="ftnt_ref8">[8]</a></sup><span>&nbsp;Pain, distress, and suffering qualify as moderate activation/arousal and unpleasant/negative valence on Russell&rsquo;s </span><span class="c4"><a class="c9" href="https://psycnet.apa.org/record/1981-25062-001">circumplex model</a></span><span>&nbsp;of</span><span class="c4"><a class="c9" href="https://psycnet.apa.org/record/2011-12874-001">&nbsp;core affect</a></span><span>. The APA&rsquo;s emphasis on &ldquo;experience&rdquo; might also suggest the presence of a cognitive appraisal of &ldquo;pain&rdquo; that results in &ldquo;suffering&rdquo;, consistent with </span><span class="c4"><a class="c9" href="https://www.tandfonline.com/doi/abs/10.1080/02699931.2015.1074548?journalCode%3Dpcem20">cognitive appraisal theories of emotion</a></span><span>, and with </span><span class="c4"><a class="c9" href="https://www.jpain.org/article/S1526-5900(14)00563-X/fulltext">effects of appraisals found on chronic pain experiences and coping</a></span><span class="c3 c13">. It is also worth noting that &ldquo;suffering&rdquo; may be a protracted experience resulting from ongoing situations like chronic pain or difficult living conditions. In this case, &ldquo;suffering&rdquo; might be classified as more akin to a feeling, sentiment, or mood than it is to an emotion. </span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span>The APA&rsquo;s emphasis on experience is consistent with </span><span class="c4"><a class="c9" href="https://peh-med.biomedcentral.com/articles/10.1186/s13010-017-0049-5">philosophical</a></span><span>&nbsp;and </span><span class="c4"><a class="c9" href="https://europepmc.org/article/med/10870733">clinical</a></span><span>&nbsp;perspectives on suffering as an emergent property of painful sensation. This definition also accords with humans&rsquo; tendency</span><span>&nbsp;to think that if a being does not &ldquo;feel&rdquo; or is not aware of their affective states then they cannot &ldquo;suffer.&rdquo;</span><sup><a href="#ftnt9" id="ftnt_ref9">[9]</a></sup><span>&nbsp;</span><span>For instance</span><span>, </span><span class="c4"><a class="c9" href="https://www.sciencedirect.com/science/article/pii/S0195666310003648?via%253Dihub">one study</a></span><span>&nbsp;found that meat consumption was linked to the denial of the mental states (e.g., &ldquo;pain&rdquo;) thought to be necessary for nonhuman animals to suffer. This type of sentience denial has been used to justify the maltreatment of numerous nonhuman animals</span><sup><a href="#ftnt10" id="ftnt_ref10">[10]</a></sup><span>&nbsp;as well as humans in other social groups throughout history.</span><sup><a href="#ftnt11" id="ftnt_ref11">[11]</a></sup><span class="c3 c13">&nbsp;</span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span class="c4"><a class="c9" href="https://www.sentienceinstitute.org/downloads/Perspective%20taking%20and%20nonhuman%20groups%20-%20preprint.pdf">Some of our research</a></span><span>&nbsp;</span><span>suggests</span><span>&nbsp;that sentient artificial entities may be subject to substrate-based moral exclusion. Substratism entails the devaluing of artificial entities based on their artificial (e.g., silicon-based), non-carbon material composition in a psychological process similar to speciesism.</span><sup><a href="#ftnt12" id="ftnt_ref12">[12]</a></sup><span>&nbsp;Speciesist attitudes prioritize the moral value of humans over nonhuman animals and some nonhuman animals over other nonhuman animals. Speciesism and substratism can be thought of as prejudiced attitudes towards nonhumans. </span><span class="c4"><a class="c9" href="https://pubmed.ncbi.nlm.nih.gov/29517258/">Psychological research</a></span><span>&nbsp;has shown that a preference for human social hierarchy in which (supposedly) powerful human groups dominate (supposedly) weaker human groups (a personality trait psychologists refer to as social dominance orientation) </span><span>underpins </span><span>speciesism.</span><sup><a href="#ftnt13" id="ftnt_ref13">[13]</a></sup><span>&nbsp;Both social dominance orientation and speciesism contribute to moral exclusion.</span><sup><a href="#ftnt14" id="ftnt_ref14">[14]</a></sup><span class="c3 c13">&nbsp;It seems likely that substratism may have a similar effect on the moral exclusion of artificial entities. </span></p><h2 class="c22 c19" id="h.a15qcdqgmc68"><span>Social robots and humans</span></h2><p class="c10"><span class="c23">Note. This section highlights a small portion of the research on social robots relevant to moral consideration, coming from a psychological science perspective. For more information on the extensive literature on social robots from educational, clinical, developmental, and HRI perspectives, see the section below on </span><span class="c4 c23"><a class="c9" href="#h.cd7cszqe7jhm">interpersonal interactions</a></span><span class="c23">&nbsp;and the following links to meta-analytic and review articles: </span><span class="c4 c23"><a class="c9" href="https://dl.acm.org/doi/abs/10.5898/JHRI.6.1.Admoni">Admoni and Scassellati (2017)</a></span><span class="c23">, </span><span class="c4 c23"><a class="c9" href="https://robotics.sciencemag.org/content/robotics/3/21/eaat5954.full.pdf?casa_token%3DlZadCudBNAUAAAAA:X1h1-W_Mhit7tCedyLOhCCmqzL1sMmV5kwWj4IO5yDVN_rCSKPSSJgGBMGpHUmQiyj-nsz4dm9adhg">Belpaeme et al. (2018)</a></span><span class="c23">, </span><span class="c4 c23"><a class="c9" href="https://psycnet.apa.org/record/2009-10609-006">Broekens et al. (2009)</a></span><span class="c23">, </span><span class="c4 c23"><a class="c9" href="https://ruj.uj.edu.pl/xmlui/handle/item/42187">Campa (2016)</a></span><span class="c23">, </span><span class="c4 c23"><a class="c9" href="https://sigmapubs.onlinelibrary.wiley.com/doi/pdfdirect/10.1111/jnu.12423">Chen et al. (2018)</a></span><span class="c23">, </span><span class="c4 c23"><a class="c9" href="https://journals.sagepub.com/doi/full/10.1037/gpr0000007?casa_token%3DhH9X5KioqhYAAAAA%253AkUlY_RpimykF-mmXWfv1moaCed1Mf-ee2nFZElWm18sHTBK1GznTo32vMr1Zb_TJVZF8htOSzM4P">Costescu et al. (2014)</a></span><span class="c23">, </span><span class="c4 c23"><a class="c9" href="https://journals.sagepub.com/doi/full/10.1177/0018720811417254?casa_token%3DYhOxQfhW9xYAAAAA%253AZxF89cY07eJav3EDUkbOOpbLf3FsKoJg7ILWcY_DAZVT9bTfZLGlIodO67p789PJiObAwoUncAWW">Hancock et al. (2011)</a></span><span class="c23">, </span><span class="c4 c23"><a class="c9" href="https://journals.sagepub.com/doi/full/10.1177/0018720820922080?casa_token%3Dt9l8D4GxGAAAAAAA%253ADBSBCy2Y3TaAebUE4nG9jlhCJ3yGIlgwSsO7yxxjBxQ01tBUA1n3GU-ytfWsRr-sCnXIAz6fpmqr">Hancock et al. (2020)</a></span><span class="c23">, </span><span class="c4 c23"><a class="c9" href="https://pubmed.ncbi.nlm.nih.gov/33361589/">Hirt et al. (2021)</a></span><span class="c23">, </span><span class="c4 c23"><a class="c9" href="https://link.springer.com/content/pdf/10.1186/s12877-019-1244-6.pdf">Hung et al. (2019)</a></span><span class="c23">, </span><span class="c4 c23"><a class="c9" href="https://www.sciencedirect.com/science/article/pii/S0272494419303846?casa_token%3D-M5PWZPXVTYAAAAA:v1dRyDS39HK3WfQGLNmUXn_0Nkb1LjXp3LtsanRSz3wY2GrgcbbH8P5e_sFbyFLDWOOm5AkUeA">Leichtmann and Nitsch (2021)</a></span><span class="c23">, </span><span class="c4 c23"><a class="c9" href="https://academic.oup.com/gerontologist/article/59/1/e37/5036100">Pu et al. (2019)</a></span><span class="c23">, </span><span class="c4 c23"><a class="c9" href="https://link.springer.com/content/pdf/10.1007/978-3-030-38778-5_38.pdf">Rosanda and Starcic (2020)</a></span><span class="c23">, </span><span class="c4 c23"><a class="c9" href="https://www.jmir.org/2019/7/e13322">Scoglio et al. (2019)</a></span><span class="c23">, </span><span class="c4 c23"><a class="c9" href="https://www.mdpi.com/1424-8220/20/18/5087">Song and Luximon (2020)</a></span><span class="c23">, </span><span class="c4 c23"><a class="c9" href="https://link.springer.com/article/10.1007/s12369-020-00736-8">Stower et al. (2021)</a></span>.</p><p class="c7"><span class="c45 c23 c13"></span></p><p class="c10"><span>Perhaps when you think about robots, the first image that comes to your mind is of an industrial working arm bolting car parts together. Indeed, robots like this have been used for a long time in industrial settings like car manufacturing. However, humans are social beings who have been designing robots for healthcare, education, entertainment, and social companionship purposes. These social robots are embodied, at least partly autonomous, and designed to routinely interact with humans.</span><sup><a href="#ftnt15" id="ftnt_ref15">[15]</a></sup><span>&nbsp;</span><span class="c4"><a class="c9" href="https://www.apa.org/members/content/robot-companion">For example</a></span><span class="c3 c13">, several companion robots that are intended to help relieve anxiety, depression, and loneliness are currently available for humans to bring into their homes. </span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span>Psychologists have suggested that the increasing extent and quality of social interaction between humans and social robots necessitates more consideration of their moral status and their rights based on their social roles,</span><sup><a href="#ftnt16" id="ftnt_ref16">[16]</a></sup><span>&nbsp;for instance considerations of </span><span class="c4"><a class="c9" href="https://www.britishcouncil.org/anyone-anywhere/explore/digital-identities/robots-citizens">citizenship</a></span><span>&nbsp;rights</span><span class="c3 c13">. That is, we need to think more about social robots&rsquo; rights because we form bonds with them and consider them to have certain social standings.</span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span class="c4"><a class="c9" href="https://onlinelibrary.wiley.com/doi/pdf/10.1111/spc3.12489?casa_token%3DR72YLVqOwmwAAAAA:ET_xrlcUCF7ZBaouy0tHnoybBhMMBk0DZ3GItrxOxSfsbdvmNmbODk4wVPHjyx_s4DPWlEkRRl6jUA">Social psychological research</a></span><span>&nbsp;has suggested that humans will relate to social robots based on the same principles witnessed in human intergroup relations. For instance, </span><span>positive emotions felt towards robots, much like positive emotions felt towards a human outgroup, have been found to predict a greater willingness to interact with them.</span><sup><a href="#ftnt17" id="ftnt_ref17">[17]</a></sup><span class="c3 c13">&nbsp;This research suggests that human-robot intergroup relations may be an important area of study that could be applied to understanding how humans extend moral consideration to sentient artificial entities.</span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span>Psychologists have also shown that humans attribute more emotional capacity to social robots than to robots with an economic purpose. Humans protected social robots over economic robots from the harm of receiving painful electric shocks in </span><span class="c4"><a class="c9" href="https://www.frontiersin.org/articles/10.3389/fpsyg.2018.01230/full">one study</a></span><span>. </span><span>In this study, recognizing the emotional capacity of these social robots increased concern for their well-being. An implication of this research is that humans&rsquo; recognition of artificial sentience may be critical for their moral inclusion.</span></p><h2 class="c19 c40" id="h.x2brpfwc6xqn"><span class="c3 c32">AI and humans</span></h2><p class="c10"><span>Since the advent of AI there have been numerous questions about the </span><span class="c4"><a class="c9" href="https://www.theguardian.com/inequality/2017/aug/08/rise-of-the-racist-robots-how-ai-is-learning-all-our-worst-impulses">biases of AIs</a></span><span>. Recently, there have been high-profile </span><span>examples of AIs committing moral violations against humans, from making </span><span class="c4"><a class="c9" href="https://www.nature.com/articles/d41586-019-03228-6">racist healthcare decisions</a></span><span>&nbsp;to </span><span class="c4"><a class="c9" href="https://www.bbc.com/news/world-us-canada-43497364">autonomous vehicle crashes resulting in human deaths</a></span><span>&nbsp;to </span><span class="c4"><a class="c9" href="https://www.vice.com/en/article/y3gj3v/sexist-ai-is-even-more-sexist-than-we-thought">generating overly sexualized images of women</a></span><span>. </span><span class="c4"><a class="c9" href="https://psycnet.apa.org/record/2018-30432-040">Psychological research</a></span><span>&nbsp;has shown that humans will hold AIs accountable for these moral violations, including attributing to them awareness of the violation, intentionality, and blame, despite humans&rsquo; general discomfort with </span><span class="c4"><a class="c9" href="https://www.sciencedirect.com/science/article/pii/S0010027718302087?casa_token%3D4OJ9JcqyXtcAAAAA:4v-E_Fx2n-PePtcMjrrsi61Qvu0DyZKr5D6PaVYl3ztZpphC7F1CGg_lTp1d8ONDPYi7xzgzhw">machines making moral decisions</a></span><span>. </span><span>The converse of this relationship,</span><sup><a href="#ftnt18" id="ftnt_ref18">[18]</a></sup><span>&nbsp;that AIs could experience harm or suffering as a result of their own or others&rsquo; actions against them, has not been considered in depth in psychological science.</span><span>&nbsp;Although, </span><span class="c4"><a class="c9" href="https://journals.sagepub.com/doi/10.1177/0956797612472343">one study</a></span><span>&nbsp;showed that people who read about the intentional physical abuse of a complex social robot by a scientist attributed the robot more mind and more capacity to feel pain than people who read that the scientist performed their job satisfactorily. </span><span class="c4"><a class="c9" href="https://journals.sagepub.com/doi/abs/10.1177/0301006618809919">Another similar study</a></span><span>&nbsp;</span><span>showed that</span><span>&nbsp;humans who saw a facial wound on a human-like robotic avatar or on a human avatar attributed that avatar more mind and capacity to feel pain than unharmed robotic or human avatars. The human avatar was also evaluated as having more mind and capacity to feel pain than the robotic avatar. These studies suggest that visible and physical harms to human-like entities may increase their moral consideration to some degree. Whether these effects generalize to all harms and all AIs or are limited to physical wounds, social robots, or other human-like entities is unknown.</span><sup><a href="#ftnt19" id="ftnt_ref19">[19]</a></sup></p><h2 class="c40 c19" id="h.ktdqz6qq35fb"><span class="c3 c32">Psychology, neuroscience, and AI</span></h2><p class="c10"><span>Psychology and neuroscience have contributed substantially to how we think about knowledge constructs critical to AI development such as problem-solving, learning and memory, emotion recognition, and neural networks.</span><sup><a href="#ftnt20" id="ftnt_ref20">[20]</a></sup><span>&nbsp;If we accept that </span><span class="c4"><a class="c9" href="https://www.ibm.com/cloud/learn/what-is-artificial-intelligence">the field of artificial intelligence aims to create intelligent machines and programs</a></span><span>,</span><sup><a href="#ftnt21" id="ftnt_ref21">[21]</a></sup><span class="c3 c13">&nbsp;then we also benefit from considering the connections between how psychological science explains cognition and emotion and how artificial intelligence expresses cognitive and emotional functions. </span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span class="c4"><a class="c9" href="https://www.sciencedirect.com/topics/neuroscience/reinforcement-learning">Reinforcement learning (RL)</a></span><span>, an </span><span class="c4"><a class="c9" href="https://www.amazon.science/latest-news/3-ways-reinforcement-learning-is-changing-the-world-around-you">increasingly prominent type of artificial intelligence</a></span><span>, is closely related to </span><span class="c4"><a class="c9" href="https://dictionary.apa.org/operant-conditioning">theories of instrumental learning in psychology</a></span><span>&nbsp;in which human and nonhuman animals </span><span class="c4"><a class="c9" href="https://www.verywellmind.com/operant-conditioning-a2-2794863">learn based on a series of rewards and punishments</a></span><span>. RL algorithms rely on goal accomplishment to learn the appropriate behaviors in their system.</span><sup><a href="#ftnt22" id="ftnt_ref22">[22]</a></sup><span>&nbsp;RL algorithms focus on optimizing specific rewards in their environments to achieve their goals. For example, when an AI defeats a human in a game of chess, we would consider this a successful application of RL in which the AI has optimized the positive rewards in its system. What happens when the AI instead fails? The AI might face impeded goal achievement and continual punishment in the system for failing to optimize. A human or nonhuman animal in these conditions might exhibit frustration, anger, or anxiety at failing to achieve their goal, with suffering as a possible consequence. Given that the fundamental learning processes of these AIs mirror those that lead to suffering in natural entities, </span><span class="c4"><a class="c9" href="https://arxiv.org/abs/1410.8233">some have suggested</a></span><span>&nbsp;that this merits giving them moral consideration</span><span>. </span></p><h2 class="c19 c22" id="h.cd7cszqe7jhm"><span class="c3 c32">Interpersonal interactions with artificial entities</span></h2><p class="c10"><span class="c3 c13">Facilitating harmonious, productive interactions between humans and artificial entities has been a multidisciplinary topic of research including some psychological studies. Below we summarize some influential studies from this domain. We seek to provide a general overview of the outcomes of interpersonal interactions that researchers have focused on or that showcase unique areas of growing scholarship. Within this survey of the literature we endeavor to showcase highly cited papers (i.e., well-known, widely regarded, generative), novel approaches, and outcomes relevant to moral consideration. Additionally, where possible, we prioritized studies in which humans directly interacted with artificial entities. The following list is by no means exhaustive of the research on humans&rsquo; interactions with artificial entities.</span></p><p class="c12"><span class="c3 c13"></span></p><p class="c17"><span class="c23">Table 3:</span><span class="c3 c13">&nbsp;Interpersonal interaction studies</span></p><p class="c12"><span class="c3 c13"></span></p><a id="t.ead48aa4a4726f157bdd86e297b4da3412aa2a7b"></a><a id="t.2"></a><table class="c29"><tbody><tr class="c25"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c16 c13">Outcome</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c16 c13">Entity type</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c16 c13">Effect</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c38">Study (Google Scholar &ldquo;cited by&rdquo; index on 4 August 2021)</span></p></td></tr><tr class="c25"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Attribution of intelligence</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Computer program, functional robot, human-like robot</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Humans attributed more intelligence to the human-like robot following interaction in a Prisoner&rsquo;s Game Dilemma.</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://ieeexplore.ieee.org/abstract/document/4600728/metrics#metrics">Hegel et al., 2008</a></span><span class="c3 c1">&nbsp;(103)</span></p><p class="c6 c39"><span class="c3 c1"></span></p></td></tr><tr class="c25"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Compliance</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Nursebot robot</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Humans complied more with robots displaying social cues congruent to their jobs (e.g., a serious robot for an exercise instructor). </span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://ieeexplore.ieee.org/abstract/document/1251796">Goetz et al., 2003</a></span><span class="c1">&nbsp;</span><span class="c3 c1">(788)</span></p></td></tr><tr class="c25"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Trust</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Virtual mechanomorphic guidance robot</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Initial trust in an unknown robot decreased when the robot made a single mistake, especially in a high risk situation.</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber%3D7828078%26casa_token%3DTJGNNS8AlxUAAAAA:ZfMhvMUEhqpK6RoTRB8F3De3BdqTmXwmlwFghdH70HCP0GexVv2Hr5EgSZDO5pToDp9JaI2X5A">Robinette et al., 2017</a></span><span class="c3 c1">&nbsp;(80)</span></p></td></tr><tr class="c25"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Willingness to interact</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Mechanomorphic iRobot Create robot, Beam+ telepresence robot, human-like Nao robot, human-like Baxter robot, seal-like Paro robot, dinosaur-like Pleo robot</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Following interaction with robots, humans who felt more positively about robots were more likely to be willing to interact with robots in future situations.</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://journals.sagepub.com/doi/10.1177/0146167219900439">Smith et al., 2020</a></span><span class="c1">&nbsp;(6)</span></p></td></tr><tr class="c48"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Perceived threat</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Mechanomorphic iRobot Create robot</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Humans felt more threatened by entitative (similar in appearance and action) robot groups than by diverse (different in appearance and action) robot groups. </span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://dl.acm.org/doi/10.1145/2909824.3020248">Fraune et al., 2017</a></span><span class="c1">&nbsp;(35)</span></p></td></tr><tr class="c25"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Negative attitudes</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Human-like Robovie robot</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Humans with more negative attitudes towards robots took longer to talk to a co-present robot.</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://ieeexplore.ieee.org/abstract/document/1374726">Nomura et al., 2004</a></span><span class="c3 c1">&nbsp;(144)</span></p></td></tr><tr class="c25"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Social eye gaze</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Animal-like IPRobot-PHONE</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c1">Mutual gaze (i.e., eye contact)</span><span class="c3 c1">&nbsp;with the robot increased positive evaluations of the robot.</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://dl.acm.org/doi/abs/10.1145/1322192.1322218?casa_token%3D0aDdOjdEXwMAAAAA:ajziQVlpyyUe-dEvlP6EmO1upfQWT4rAe7HHJmVphp4zG8eDfXKBuW0yQrCJzqBgt-17Kjee0GSb">Yonezawa et al., 2007</a></span><span class="c3 c1">&nbsp;(82)</span></p></td></tr><tr class="c25"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Collaborative performance</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Human-like Robovie robot, human-like Geminoid robot</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Human-robot pairs in a game performed better when the robot revealed their choice by briefly looking at it before the human had to make a congruent choice.</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://dl.acm.org/doi/abs/10.1145/1514095.1514110?casa_token%3DeVsgjsTzWX0AAAAA:DZF3sE1Nf3qDdY3iKpzBRM6AQ5S0rRXKun1ZpnTuvgBkJXiRDFRlV4JO1A7NtmQe3lwygXKofsnM">Mutlu et al., 2009 </a></span><span class="c3 c1">(195)</span></p></td></tr><tr class="c25"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Moral standing</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">AIBO robot dog</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Children rated a robot dog as deserving only slightly less moral standing than a live dog (e.g., children said it was not okay to hit the robot dog and it was not okay to hit the live dog).</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://www.sciencedirect.com/science/article/pii/S0193397308001329?casa_token%3DAwyaFoVEd48AAAAA:FPw54leYkdypvhHzHZbn12Nll5jwS2OPgcO6A7jaG0U5PlzxFxUXIwzw28MW0-BmYwVrQKsNQQ">Melson et al., 2009</a></span><span class="c3 c1">&nbsp;(143)</span></p></td></tr><tr class="c25"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Language learning</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c1 c3">Human-like Robovie robot</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Children who formed a relationship with the robot over a two-week interval at school showed increased learning of a second language.</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://www.tandfonline.com/doi/abs/10.1080/07370024.2004.9667340?casa_token%3D_f9i-kmai3UAAAAA:iqzTI730EiH-Rltws1ly99DrV-30x1Ed1F-RU5VCkxA30VoioZhU1kyla9ZEZfqiXO9wWMbPYg_G">Kanada et al., 2004</a></span><span class="c3 c1">&nbsp;(1097)</span></p></td></tr><tr class="c25"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Cognitive learning</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Animal-like Keepon robot</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Interacting with an embodied robot providing personalized feedback improved adult humans&rsquo; performance on a puzzle task.</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://escholarship.org/uc/item/7ck0p200">Leyzberg et al., 2012</a></span><span class="c3 c1">&nbsp;(241)</span></p></td></tr><tr class="c25"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Interaction preference</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Embodied and virtual human-like Bandit robot</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Older adults preferred interacting with the embodied robot exercise coach than interacting with the virtual robot coach.</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://dl.acm.org/doi/abs/10.5898/JHRI.2.2.Fasola">Fasola &amp; Matari&#263;, 2013</a></span><span class="c3 c1">&nbsp;(334)</span></p></td></tr><tr class="c25"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Bullying</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Mechanomorphic DustBot robot, mechanomorphic Piero robot</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Service robots (e.g., trash removal) operating in an urban environment demonstration were subject to aggressive behaviors like kicking and slapping, especially by younger adults, when the robots were unsupervised by human controllers.</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://ieeexplore.ieee.org/abstract/document/5654677?casa_token%3D7B8FCixNMv4AAAAA:3RRU-MCrlKX3RVROPIl2WhzIbwoHuanCMtWUE0MYabojg_CPRXKIlViTIkA9UAWWNy_kXQRtGQ">Salvini et al., 2010</a></span><span class="c3 c1">&nbsp;(74)</span></p></td></tr><tr class="c25"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Abuse</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Human-like robot</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c3 c1">Adults were more likely to deliver intense shocks to robots than to humans even when the robot uttered statements like, &ldquo;That was too painful, the shocks are hurting me.&rdquo;</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c0"><a class="c9" href="https://www.jbe-platform.com/content/journals/10.1075/is.9.3.04bar">Bartneck &amp; Hu, 2008</a></span><span class="c3 c1">&nbsp;(76)</span></p></td></tr></tbody></table><h1 class="c44 c19" id="h.koo5wb5t6x1k"><span class="c3 c27">What psychological science research would help better inform our understanding of artificial sentience?</span></h1><p class="c10"><span>At Sentience Institute, </span><span class="c4"><a class="c9" href="https://www.sentienceinstitute.org/research-agenda">some of our research</a></span><span>&nbsp;aims to understand how and why humans might extend moral consideration to artificial entities </span><span>based on humans&rsquo; ability to take the perspective of nonhumans</span><span class="c3 c13">, on human psychological characteristics predictive of moral consideration, and on artificial entities&rsquo; features. We hope that this research will grow the conversation amongst researchers around the importance of studying the moral consideration of artificial entities.</span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span>More research is needed on the moral consideration of artificial entities, especially regarding future entities with the potential to have some degree of sentience. Although psychological science has begun to investigate the moral consideration of current artificial entities and has begun contributing to the research on social interactions between artificial entities and humans, there is very little research that focuses, either explicitly or implicitly, on topics consequential to the moral consideration of future sentient artificial entities. For instance, research could question when, why, and how people might or might not value the sentience of artificial entities, which framings and types of interventions (e.g., social norms, values, mindsets) might best increase the moral inclusion of sentient artificial entities, and which psychological and situational factors might increase moral circle inclusion in the present and for the long-term future.</span><sup><a href="#ftnt23" id="ftnt_ref23">[23]</a></sup><span class="c3 c13">&nbsp;Another open question is whether or not there is a capacity limit for the moral consideration of nonhumans that will affect how nonhuman animals and sentient artificial entities are treated.</span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span class="c3 c13">Psychological research could also question whether experiences of time and psychological distance shape the moral inclusion of artificial entities, given that artificial sentience is tied to future artificial entities, as well as studying the types of psychological processes that influence which types of artificial entities will be granted moral consideration. What types of threats to humanity will increase or decrease moral consideration? Will interventions need to be different for embodied social robots who routinely interact with humans and virtual AI algorithms who are largely unseen by humans? There may be vastly more AI algorithms in the future at risk of less consideration than social robots, just as insects are more numerous than other animals but receive less consideration than mammals like chimpanzees, elephants, and dolphins.</span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span>Likewise, little is known about substratism and the psychological tendency to delegitimize entities based on their material composition. </span><span>We can seek some insight from </span><span class="c4"><a class="c9" href="https://pubmed.ncbi.nlm.nih.gov/11220444/">studies of social stigmas eliciting threat </a></span><span>such as </span><span class="c4"><a class="c9" href="https://www.researchgate.net/profile/Kristof-Vaes/publication/267075539_Product_Stigmaticity_Understanding_Measuring_and_Managing_Product-Related_Stigma/links/5444d99e0cf2e6f0c0fbcfea/Product-Stigmaticity-Understanding-Measuring-and-Managing-Product-Related-Stigma.pdf">stigma associated with prosthetics</a></span><span>.</span><sup><a href="#ftnt24" id="ftnt_ref24">[24]</a></sup><span>&nbsp;We can also seek insight from </span><span class="c4"><a class="c9" href="https://www.sciencedirect.com/science/article/abs/pii/S0195666320308527?via%253Dihub">studies of the (un)naturalness of cultured meat</a></span><span>.</span><sup><a href="#ftnt25" id="ftnt_ref25">[25]</a></sup><span>&nbsp;R</span><span class="c3 c13">esearch growth in the area of substratism could more accurately illuminate the moral exclusion of current and future artificial entities who are materially different from fully biological entities and &ldquo;unnatural&rdquo; in the origin of their sentience and the material composition of their minds.</span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span>Another neglected area important for advancing the moral consideration of artificial entities regards how humans think about the autonomy of social robots. One </span><span class="c4"><a class="c9" href="https://dl.acm.org/doi/10.1145/3415206">HRI study</a></span><span>&nbsp;found that describing artificial entities as being &ldquo;fully autonomous&rdquo; led to greater support for their rights (e.g., the right to free speech).</span><sup><a href="#ftnt26" id="ftnt_ref26">[26]</a></sup><span>&nbsp;Extrapolating from HRI research such as this, humans may perceive robots as more emotional than they were designed to be and grant them more moral consideration because of their emotional and autonomous behavior.</span><sup><a href="#ftnt27" id="ftnt_ref27">[27]</a></sup><span>&nbsp;However, </span><span class="c4"><a class="c9" href="https://www.sciencedirect.com/science/article/pii/S1071581916301768?casa_token%3DZ066IryWbK8AAAAA:R-CJ0IW49-wE85Oc-hgrZDDf0z9djr5p__0FhzQ-JE9duPJKTCo0LtQ1wLvbXxtyOON1YU6etA">another study</a></span><span>&nbsp;found that autonomous behavior increased perceptions of uniqueness and safety threats, leading to more negative attitudes towards robots and opposition to robotics research. Is the autonomous behavior of a virtual AI (e.g., an algorithm or program) as threatening as the autonomous behavior of an embodied AI? Is autonomous behavior more or less threatening if an entity is sentient? Does an entity&rsquo;s expression of sentience signify greater autonomy? More studies on the interaction between autonomy and sentience need to be undertaken to disentangle the positive and negative effects that autonomy has on humans&rsquo; moral consideration of sentient artificial entities. </span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span class="c3 c13">Finally, how should we think about entities who can take moral actions but who are not given moral consideration even when others are responsible for teaching them immoral, unfair, or biased strategies? For instance, is it acceptable to blame an AI for making a biased decision based on information and goals provided exclusively by humans? Should humans destroy the AI for succeeding if the outcome is dangerous for humans? What if the AI was able to process pain, feel distressed, and suffer or to experience joy and feelings of success? </span></p><h1 class="c19 c44" id="h.n1o62923fhnt"><span class="c3 c27">How could we apply knowledge about the moral inclusion of artificial entities to improving the future?</span></h1><p class="c10"><span>Understanding the psychological science behind how people include artificial entities in their moral circles may be used to encourage moral circle expansion to foster a more morally inclusive society. Knowing more about how, when, and why people include artificial entities may help us to build better interventions promoting individuals&rsquo; moral circle expansion. For instance, social psychological interventions, ranging from brief cognitive, emotional, or social &lsquo;nudges&rsquo; to extensive campaigns that change social norms, have been employed to </span><span class="c4"><a class="c9" href="https://www.annualreviews.org/doi/abs/10.1146/annurev-psych-071620-030619">reduce human prejudices against other humans</a></span><span>, to </span><span class="c4"><a class="c9" href="https://www.sciencedirect.com/science/article/pii/S0921800915301543?via%253Dihub">encourage pro-environmental behavior</a></span><span>, and to </span><span class="c4"><a class="c9" href="https://journals.sagepub.com/doi/10.1177/1948550619893959">reduce speciesism</a></span><span class="c3 c13">.</span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span>Additionally, research-based evidence from intervention studies </span><span>may aid legislators and policy makers in designing and implementing effective, tractable societal solutions that expand the moral circle to include sentient AIs without threatening or devaluing the interests of human and nonhuman animals. </span><span>Some scholars have begun to consider the socio-political and legal structures that may need to be in place for society to successfully integrate sentient artificial entities, such as by modeling legal frameworks for the protection of artificial entities on existing legislation about </span><span class="c4"><a class="c9" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D2044797">animal abuse</a></span><span>&nbsp;and </span><span class="c4"><a class="c9" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D3200802">nonhuman animals as sentient property</a></span><span class="c3 c13">. This strategy, however, positions the moral consideration of sentient AIs relative to the needs of humans, as has largely been the case with animals.</span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span>Building knowledge and working towards the moral inclusion of artificial entities may also be beneficial to reducing the dehumanization of other human groups and the moral exclusion of nonhuman animals. The prosocial treatment of social robots </span><span class="c4"><a class="c9" href="https://link.springer.com/article/10.1007/s12369-019-00583-2">may generalize</a></span><span>&nbsp;to increased prosocial treatment of other human and nonhuman animals. </span><span class="c4"><a class="c9" href="https://pubmed.ncbi.nlm.nih.gov/31916781/">Another study</a></span><span>&nbsp;suggested that a robot workforce could prompt a sense of shared humanity that would reduce human-human intergroup prejudice. However, </span><span class="c4"><a class="c9" href="https://journals.sagepub.com/doi/pdf/10.1177/0956797620929977">some research</a></span><span class="c3 c13">&nbsp;has also found that workforce automation may lead to increased human intergroup prejudice. Understanding when and why moral consideration generalizes to human and nonhuman animals after interaction with social robots and AIs might help us to explain and promote moral circle expansion.</span></p><p class="c7"><span class="c3 c13"></span></p><p class="c10"><span>We feel confident in suggesting that furthering the psychological science behind how humans perceive and interact with sentient artificial entities as individuals and as members of a group will help us to build the epistemological foundation for interventions and strategies that serve to benefit future </span><span>humans </span><span class="c3 c13">and sentient artificial entities.</span></p><h1 class="c15" id="h.ubazmtyen5v5"><span>Further Reading</span></h1><p class="c17"><span class="c4"><a class="c9" href="https://spssi.onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-4560.1990.tb00268.x">Moral exclusion and injustice: An introduction</a></span></p><p class="c17"><span class="c4"><a class="c9" href="https://journals.sagepub.com/doi/10.1177/0963721417730888">Toward a psychology of moral expansiveness</a></span></p><p class="c17"><span class="c4"><a class="c9" href="https://www.sciencedirect.com/science/article/pii/S0016328721000641?via%253Dihub">Moral circle expansion: A promising strategy to impact the far future </a></span></p><p class="c17"><span class="c4"><a class="c9" href="https://www.jstor.org/stable/41318090?seq%3D1#metadata_info_tab_contents">Moral maturation and moral conation: A capacity approach to explaining moral thought and action</a></span></p><p class="c17"><span class="c4"><a class="c9" href="https://www.sciencedirect.com/science/article/abs/pii/S1364661319300634">Holding robots responsible: The elements of machine morality</a></span></p><div><p class="c7"><span class="c45 c23 c13"></span></p><p class="c12"><span class="c3 c13"></span></p></div><hr class="c37"><div><p class="c6 c19"><a href="#ftnt_ref1" id="ftnt1">[1]</a><span class="c1">&nbsp;See a </span><span class="c0"><a class="c9" href="https://www.sciencedirect.com/science/article/pii/S0016328721000641?via%253Dihub">recent review</a></span><span class="c3 c1">&nbsp;by Anthis and Paez (2021).</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref2" id="ftnt2">[2]</a><span class="c1">&nbsp;Paraphrasing from </span><span class="c0"><a class="c9" href="https://www.sciencedirect.com/science/article/abs/pii/S0022103108001613">Laham (2009)</a></span><span class="c1">.</span><span class="c3 c1">&nbsp;</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref3" id="ftnt3">[3]</a><span class="c1">&nbsp;See </span><span class="c0"><a class="c9" href="https://psycnet.apa.org/record/2016-01230-001">Crimston et al. (2016)</a></span><span class="c1">&nbsp;and </span><span class="c0"><a class="c9" href="https://journals.sagepub.com/doi/10.1177/0963721417730888">Crimston et al. (2018)</a></span><span class="c3 c1">.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref4" id="ftnt4">[4]</a><span class="c1">&nbsp;See </span><span class="c0"><a class="c9" href="https://www.sciencedirect.com/science/article/pii/S0065260119300176?via%253Dihub">Epley and Eyal (2019)</a></span><span class="c3 c1">&nbsp;for more on this dynamic.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref5" id="ftnt5">[5]</a><span class="c1">&nbsp;Following from </span><span class="c0"><a class="c9" href="https://onlinelibrary.wiley.com/doi/full/10.1002/hbe2.147">Giger et al. (2019)</a></span><span class="c1">, </span><span class="c0"><a class="c9" href="https://pubmed.ncbi.nlm.nih.gov/33211545/">Nijssen et al. (2020)</a></span><span class="c1">, and </span><span class="c0"><a class="c9" href="https://guilfordjournals.com/doi/10.1521/soco.2019.37.1.41">Nijssen et al. (2019)</a></span><span class="c1">.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref6" id="ftnt6">[6]</a><span class="c1">&nbsp;For example, </span><span class="c0"><a class="c9" href="https://science.sciencemag.org/content/315/5812/619.full">Gray et al. (2007)</a></span><span class="c1">&nbsp;and </span><span class="c0"><a class="c9" href="https://www.sciencedirect.com/science/article/abs/pii/S0010027712001278?via%253Dihub">Gray and Wegner (2012)</a></span><span class="c1">.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref7" id="ftnt7">[7]</a><span class="c1">&nbsp;See these articles for more details on terminology: </span><span class="c0"><a class="c9" href="https://psycnet.apa.org/record/2007-11239-016">Schwarz and Clore (2007)</a></span><span class="c1">, </span><span class="c0"><a class="c9" href="https://www.ingentaconnect.com/content/imp/jcs/2005/00000012/f0030008/art00002">Russell (2005)</a></span><span class="c1">, </span><span class="c0"><a class="c9" href="https://pubmed.ncbi.nlm.nih.gov/12529060/">Russell (2003)</a></span><span class="c1">, </span><span class="c0"><a class="c9" href="https://www.tandfonline.com/doi/pdf/10.1080/00224545.1940.9918748?casa_token%3D6HzEzJONbkkAAAAA:TzfFVA7Jk27gKzpNguGqbaqUGm4ocnzVAWsaqxLA0_hz8MuEOcCLlJOls46SQc6S6K5HAkKH_Y1q">Bertocci (1940)</a></span><span class="c3 c1">.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref8" id="ftnt8">[8]</a><span class="c1">&nbsp;See also </span><span class="c0"><a class="c9" href="https://academic.oup.com/scan/article/8/6/609/1608614">Buhle et al. (2013)</a></span><span class="c1">&nbsp;and </span><span class="c0"><a class="c9" href="https://www.nature.com/articles/s41593-017-0051-7">Kragel et al. (2018)</a></span><span class="c1">.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref9" id="ftnt9">[9]</a><span class="c1">&nbsp;See a commentary on this subject in </span><span class="c0"><a class="c9" href="https://sentientmedia.org/sentience-what-it-means-and-why-its-important/">this post</a></span><span class="c3 c1">&nbsp;by Kotzmann (2020).</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref10" id="ftnt10">[10]</a><span class="c1">&nbsp;For instance, chickens are </span><span class="c0"><a class="c9" href="https://carnegiemnh.org/counting-your-chickens-the-worlds-most-numerous-bird/">one of the most numerous birds</a></span><span class="c1">&nbsp;on the planet but they are categorized as a commodity rather than an animal </span><span class="c0"><a class="c9" href="https://link.springer.com/article/10.1007%252Fs10071-016-1064-4">(Marino, 2017)</a></span><span class="c1">&nbsp;and are subject to </span><span class="c0"><a class="c9" href="https://www.britannica.com/explore/savingearth/the-difficult-lives-and-deaths-of-factory-farmed-chickens">difficult lives</a></span><span class="c3 c1">&nbsp;primarily lived on factory farms.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref11" id="ftnt11">[11]</a><span class="c1">&nbsp;See </span><span class="c0"><a class="c9" href="https://journals.sagepub.com/doi/10.1177/0963721414525781">Loughnan et al. (2014)</a></span><span class="c1">&nbsp;and </span><span class="c0"><a class="c9" href="https://www.annualreviews.org/doi/abs/10.1146/annurev-psych-010213-115045">Haslam and Loughnan (2014)</a></span><span class="c3 c1">&nbsp;for reviews of relevant research.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref12" id="ftnt12">[12]</a><span class="c1">&nbsp;Paraphrasing from</span><span class="c1">&nbsp;</span><span class="c0"><a class="c9" href="https://www.sentienceinstitute.org/blog/the-importance-of-artificial-sentience">this post</a></span><span class="c1">&nbsp;on artificial sentience</span><span class="c3 c1">.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref13" id="ftnt13">[13]</a><span class="c1">&nbsp;See also </span><span class="c0"><a class="c9" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/per.2069">Dhont et al.&rsquo;s (2016)</a></span><span class="c3 c1">&nbsp;studies on the Social Dominance Human-Animal Relations Model. </span></p></div><div><p class="c6 c19"><a href="#ftnt_ref14" id="ftnt14">[14]</a><span class="c1">&nbsp;See </span><span class="c0"><a class="c9" href="https://pubmed.ncbi.nlm.nih.gov/29517258/">Caviola et al. (2019)</a></span><span class="c3 c1">.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref15" id="ftnt15">[15]</a><span class="c1">&nbsp;See </span><span class="c0"><a class="c9" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D2044797">Darling (2012)</a></span><span class="c3 c1">&nbsp;for more on social robots.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref16" id="ftnt16">[16]</a><span class="c1">&nbsp;See </span><span class="c0"><a class="c9" href="https://www.frontiersin.org/articles/10.3389/fpsyg.2019.01535/full">Hildt (2019)</a></span><span class="c3 c1">&nbsp;for a review and commentary. </span></p></div><div><p class="c6 c19"><a href="#ftnt_ref17" id="ftnt17">[17]</a><span class="c1">&nbsp;See </span><span class="c0"><a class="c9" href="https://tmb.apaopen.org/pub/vlke08m8/release/1">Smith et al. (2021</a></span><span class="c3 c1">). </span></p></div><div><p class="c6 c19"><a href="#ftnt_ref18" id="ftnt18">[18]</a><span class="c1">&nbsp;For more information on this duality see </span><span class="c0"><a class="c9" href="https://science.sciencemag.org/content/315/5812/619">Gray et al. (2007)</a></span><span class="c1">&nbsp;and </span><span class="c0"><a class="c9" href="https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(19)30063-4?_returnURL%3Dhttps%253A%252F%252Flinkinghub.elsevier.com%252Fretrieve%252Fpii%252FS1364661319300634%253Fshowall%253Dtrue">Bigman et al. (2019)</a></span><span class="c3 c1">.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref19" id="ftnt19">[19]</a><span class="c1">&nbsp;See </span><span class="c0"><a class="c9" href="https://journals.plos.org/plosone/article?id%3D10.1371/journal.pone.0180952">Tanibe et al., (2017)</a></span><span class="c3 c1">&nbsp;for a related study showing how perspective-taking and imagining a benevolent interaction with a human-like housework robot increases perception of that robot&rsquo;s mind.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref20" id="ftnt20">[20]</a><span class="c1">&nbsp;See </span><span class="c0"><a class="c9" href="https://www.cambridge.org/core/books/cambridge-handbook-of-the-intellectual-history-of-psychology/A8BEB9629BD07A7E3B240433753DC3AA">this handbook</a></span><span class="c1">&nbsp;for a review of the history of psychology, </span><span class="c0"><a class="c9" href="https://psycnet.apa.org/record/1950-02200-000">this seminal book</a></span><span class="c1">&nbsp;on neural pathways, </span><span class="c0"><a class="c9" href="https://www.semanticscholar.org/paper/Artificial-Psychology%3A-The-Psychology-of-AI-Crowder-Friess/6a40815cfbdcbd8629b50f2871bb3c89b38dd1e7">this paper</a></span><span class="c1">&nbsp;for a review of the psychology of AI, and </span><span class="c0"><a class="c9" href="https://link.springer.com/chapter/10.1007/978-3-030-30391-4_12">this historical perspective</a></span><span class="c3 c1">&nbsp;on cognitive science and AI.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref21" id="ftnt21">[21]</a><span class="c1">&nbsp;See also </span><span class="c0"><a class="c9" href="https://www.cin.ufpe.br/~tfl2/artificial-intelligence-modern-approach.9780131038059.25368.pdf">Russell &amp; Norvig, 1995</a></span><span class="c33">.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref22" id="ftnt22">[22]</a><span class="c1">&nbsp;See </span><span class="c0"><a class="c9" href="https://arxiv.org/abs/1410.8233">Tomasik (2014)</a></span><span class="c3 c1">&nbsp;for more depth.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref23" id="ftnt23">[23]</a><span class="c1">&nbsp;For more information on the value of the future, see </span><span class="c0"><a class="c9" href="https://centerforreducingsuffering.org/arguments-for-and-against-a-focus-on-s-risks/">this article</a></span><span class="c1">&nbsp;from Tobias Baumann (2020) and </span><span class="c0"><a class="c9" href="https://forum.effectivealtruism.org/posts/qZyshHCNkjs3TvSem/longtermism">this post</a></span><span class="c3 c1">&nbsp;from William MacAskill (2019).</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref24" id="ftnt24">[24]</a><span class="c1">&nbsp;For more on product-related stigma see </span><span class="c0"><a class="c9" href="https://www.tandfonline.com/doi/full/10.1080/09544828.2021.1879031">this article</a></span><span class="c3 c1">&nbsp;by Schr&ouml;ppel et al., (2021).</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref25" id="ftnt25">[25]</a><span class="c1">&nbsp;For more on &ldquo;naturalness&rdquo; see </span><span class="c0"><a class="c9" href="https://www.penguinrandomhouse.com/books/621092/natural-by-alan-levinovitz/">this book</a></span><span class="c3 c1">&nbsp;by Alan Levinovitz (2021).</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref26" id="ftnt26">[26]</a><span class="c1">&nbsp;Summarized from a study by </span><span class="c0"><a class="c9" href="https://dl.acm.org/doi/10.1145/3415206">Lima et al. (2020)</a></span><span class="c1">.</span></p></div><div><p class="c6 c19"><a href="#ftnt_ref27" id="ftnt27">[27]</a><span class="c1">&nbsp;Paraphrasing from </span><span class="c0"><a class="c9" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D2044797">Darling (2012)</a></span><span class="c3 c1">.</span></p></div></body></html>
</div>




    <hr>
    <div class="container newsletter-container ">
      <p>Subscribe to our newsletter to receive updates on our research and activities. We average two to five emails per year.</p>
      <div id="mc_embed_signup">
        <form action="//sentienceinstitute.us15.list-manage.com/subscribe/post?u=d898f823d035e0601866e68d6&amp;id=cbf2d915a6" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
          <div id="mc_embed_signup_scroll">
            <input type="email" value="" name="EMAIL" class="email form-input" id="mce-EMAIL" placeholder="Email address" required>
            <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
            <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_d898f823d035e0601866e68d6_cbf2d915a6" tabindex="-1" value=""></div>
            <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
          </div>
        </form>
      </div>
    </div>
    
    <footer class="footer">
      <div class="container">
        <div class="row">
          <div class="col-md-2">
            <div><span class="bold">Contact us: </span><a href="mailto:info@sentienceinstitute.org">info@sentienceinstitute.org</a></div>
            <div class="icons">
              <!-- <a href="/rss.xml"><i class="material-icons">rss_feed</i></a> -->
              <a href="https://www.facebook.com/sentienceinstitute"><img class="icon" src="../img/icons/icon_facebook_white.png"/></a>
              <a href="https://www.twitter.com/sentienceinst"><img class="icon" src="../img/icons/icon_twitter_white.png"/></a>
            </div>
          </div>
          <div class="col-md-10 last-column">
            <div>
               2018 Sentience Institute
            </div>
            <div>
              <a href="/terms">Terms and Conditions &amp; Privacy Policy</a>
            </div>
            <div>
              Thank you, <a href="https://weanimals.org/">Jo-Anne McArthur</a>, for granting us the use of so many photos.
            </div>
          </div>
        </div>
      </div>
    </footer>
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/TweenMax.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js" integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn" crossorigin="anonymous"></script>
    <script src="/js/ready.js?v=@version@"></script>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-100318911-1', 'auto');
      ga('send', 'pageview');

    </script>
    
  </body>
</html>
