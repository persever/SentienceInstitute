<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:20pt;font-family:"Arial";font-style:normal}.c10{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c8{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c11{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c2{padding-top:0pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c3{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c4{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c9{color:inherit;text-decoration:inherit}.c6{height:11pt}.c7{font-style:italic}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c4 doc-content"><p class="c2"><span>We are pleased to announce our latest peer-reviewed publication, &ldquo;Public Opinion and the Rise of Digital Minds: Perceived Risk, Trust, and Regulation Support,&rdquo; in </span><span class="c7">Public Performance &amp; Management Review</span><span class="c8">.</span></p><h1 class="c10" id="h.eesrjtqklcdf"><span class="c5">Abstract</span></h1><p class="c1" id="h.k00kl8ehvin9"><span class="c8">Governance institutions must respond to societal risks, including those posed by generative AI. This study empirically examines how public trust in institutions and AI technologies, along with perceived risks, shape preferences for AI regulation. Using the nationally representative 2023 Artificial Intelligence, Morality, and Sentience (AIMS) survey, we assess trust in government, AI companies, and AI technologies, as well as public support for regulatory measures such as slowing AI development or outright bans on advanced AI. Our findings reveal broad public support for AI regulation, with risk perception playing a significant role in shaping policy preferences. Individuals with higher trust in government favor regulation, while those with greater trust in AI companies and AI technologies are less inclined to support restrictions. Trust in government and perceived risks significantly predict preferences for both soft (e.g., slowing development) and strong (e.g., banning AI systems) regulatory interventions. These results highlight the importance of public opinion in AI governance. As AI capabilities advance, effective regulation will require balancing public concerns about risks with trust in institutions. This study provides a foundational empirical baseline for policymakers navigating AI governance and underscores the need for further research into public trust, risk perception, and regulatory strategies in the evolving AI landscape.</span></p><p class="c6 c11" id="h.oprzuy5kj8m8"><span class="c0"></span></p><p class="c1" id="h.68k03fjopr22"><span>The paper is available open access on the journal website: </span><span class="c3"><a class="c9" href="https://www.google.com/url?q=https://www.tandfonline.com/doi/full/10.1080/15309576.2025.2495094&amp;sa=D&amp;source=editors&amp;ust=1750042361805374&amp;usg=AOvVaw3ZkMExAIpIfHI6LkEK5fsW">https://www.tandfonline.com/doi/full/10.1080/15309576.2025.2495094</a></span></p><p class="c1 c6" id="h.3yuu0znnosob"><span class="c8"></span></p><p class="c1" id="h.qvsbdnmt2vy2"><span>A preprint version is available on ArXiv: </span><span class="c3"><a class="c9" href="https://www.google.com/url?q=https://arxiv.org/abs/2504.21849&amp;sa=D&amp;source=editors&amp;ust=1750042361805795&amp;usg=AOvVaw0nmVh1zfx__6cHfqK7naPB">https://arxiv.org/abs/2504.21849</a></span></p><p class="c1 c6" id="h.k7m8ohw0cf0u"><span class="c8"></span></p></body></html>